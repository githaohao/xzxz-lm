# ğŸ¤ FunAudioLLM & SenseVoice å®‰è£…é…ç½®æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

FunAudioLLM æ˜¯é˜¿é‡Œå·´å·´å¼€æºçš„é«˜æ€§èƒ½è¯­éŸ³å¤„ç†æ¡†æ¶ï¼ŒSenseVoice æ˜¯å…¶æ ¸å¿ƒçš„è¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

- âš¡ **è¶…é«˜é€Ÿåº¦**ï¼šæ¯” Whisper-Large å¿« 15 å€
- ğŸ¯ **é«˜ç²¾åº¦**ï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ° SOTA æ€§èƒ½
- ğŸŒ **å¤šè¯­è¨€**ï¼šæ”¯æŒ 50+ ç§è¯­è¨€
- ğŸ­ **æƒ…æ„Ÿè¯†åˆ«**ï¼šå†…ç½®æƒ…æ„Ÿåˆ†æå’Œå£°å­¦äº‹ä»¶æ£€æµ‹
- ğŸ“Š **å®æ—¶å¤„ç†**ï¼šæ”¯æŒæµå¼è¯­éŸ³è¯†åˆ«

## ğŸ› ï¸ ç³»ç»Ÿè¦æ±‚

### ç¡¬ä»¶è¦æ±‚
- **CPU**: 4 æ ¸å¿ƒä»¥ä¸Šï¼ˆæ¨è 8 æ ¸å¿ƒï¼‰
- **å†…å­˜**: 8GB ä»¥ä¸Šï¼ˆæ¨è 16GBï¼‰
- **GPU**: å¯é€‰ï¼ŒNVIDIA GPU å¯æ˜¾è‘—æå‡æ€§èƒ½
- **å­˜å‚¨**: è‡³å°‘ 10GB å¯ç”¨ç©ºé—´

### è½¯ä»¶è¦æ±‚
- **Python**: 3.8 - 3.11
- **PyTorch**: 1.13.0+
- **CUDA**: 11.7+ (å¦‚æœä½¿ç”¨ GPU)

## ğŸ“¦ å®‰è£…æ­¥éª¤

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n funaudio python=3.10
conda activate funaudio

# æˆ–ä½¿ç”¨ venv
python -m venv funaudio_env
source funaudio_env/bin/activate  # Linux/Mac
# funaudio_env\Scripts\activate  # Windows
```

### 2. å®‰è£… PyTorch

```bash
# CPU ç‰ˆæœ¬
pip install torch torchvision torchaudio

# GPU ç‰ˆæœ¬ (CUDA 11.8)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# GPU ç‰ˆæœ¬ (CUDA 12.1)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### 3. å®‰è£… FunASR

```bash
# å®‰è£… FunASR æ ¸å¿ƒåº“
pip install funasr

# å®‰è£…é¢å¤–ä¾èµ–
pip install modelscope
pip install soundfile
pip install librosa
```

### 4. å®‰è£…å…¶ä»–ä¾èµ–

```bash
# éŸ³é¢‘å¤„ç†
pip install ffmpeg-python
pip install webrtcvad

# æ¨¡å‹åŠ è½½
pip install transformers
pip install accelerate

# å¯é€‰ï¼šæ€§èƒ½ä¼˜åŒ–
pip install onnxruntime  # CPU æ¨ç†ä¼˜åŒ–
pip install onnxruntime-gpu  # GPU æ¨ç†ä¼˜åŒ–
```

## ğŸ”§ é…ç½® SenseVoice æ¨¡å‹

### 1. æ›´æ–°åç«¯æœåŠ¡

ç¼–è¾‘ `backend/app/services/funaudio_service.py`ï¼š

```python
import logging
import torch
import numpy as np
from typing import Optional, Dict, Any, List
from io import BytesIO
import tempfile
import os
import asyncio
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess

logger = logging.getLogger(__name__)

class FunAudioLLMService:
    """
    åŸºäºé˜¿é‡ŒFunAudioLLMçš„è¯­éŸ³æœåŠ¡
    é›†æˆSenseVoiceè¿›è¡Œé«˜æ€§èƒ½è¯­éŸ³è¯†åˆ«ã€æƒ…æ„Ÿåˆ†æå’Œå£°å­¦äº‹ä»¶æ£€æµ‹
    """
    
    def __init__(self):
        self.model = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.conversation_history: Dict[str, List[Dict[str, Any]]] = {}
        self.max_history_length = 20
        
        logger.info(f"ğŸ¤ åˆå§‹åŒ–FunAudioLLMæœåŠ¡ï¼Œè®¾å¤‡: {self.device}")
        
    async def initialize(self):
        """åˆå§‹åŒ–SenseVoiceæ¨¡å‹"""
        try:
            logger.info("ğŸ“¥ åŠ è½½SenseVoiceæ¨¡å‹...")
            
            # åŠ è½½SenseVoiceæ¨¡å‹
            self.model = AutoModel(
                model="iic/SenseVoiceSmall",  # æˆ– "iic/SenseVoiceLarge"
                trust_remote_code=True,
                vad_model="fsmn-vad",
                vad_kwargs={"max_single_segment_time": 30000},
                device=self.device,
            )
            
            logger.info("âœ… FunAudioLLM SenseVoiceæ¨¡å‹åŠ è½½æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ FunAudioLLMæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    async def voice_recognition(self, audio_data: bytes, language: str = "auto") -> Dict[str, Any]:
        """
        é«˜æ€§èƒ½è¯­éŸ³è¯†åˆ«ï¼Œæ”¯æŒæƒ…æ„Ÿåˆ†æå’Œå£°å­¦äº‹ä»¶æ£€æµ‹
        """
        try:
            if not self.model:
                await self.initialize()
            
            logger.info("ğŸ¯ å¼€å§‹FunAudioLLMè¯­éŸ³è¯†åˆ«...")
            
            # ä¿å­˜éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
            temp_audio_path = self._save_audio_temp(audio_data)
            
            try:
                # ä½¿ç”¨SenseVoiceè¿›è¡Œè¯†åˆ«
                result = self.model.generate(
                    input=temp_audio_path,
                    cache={},
                    language=language,  # "auto", "zh", "en", "yue", "ja", "ko"
                    use_itn=True,
                    batch_size_s=60,
                    merge_vad=True,
                    merge_length_s=15,
                )
                
                # å¤„ç†è¯†åˆ«ç»“æœ
                raw_text = result[0]["text"]
                processed_text = rich_transcription_postprocess(raw_text)
                
                # è§£ææƒ…æ„Ÿå’Œäº‹ä»¶ä¿¡æ¯
                emotion_info = self._extract_emotion_info(processed_text)
                event_info = self._extract_event_info(processed_text)
                clean_text = self._clean_text(processed_text)
                
                logger.info(f"âœ… è¯­éŸ³è¯†åˆ«æˆåŠŸ: {clean_text[:50]}...")
                
                return {
                    "success": True,
                    "recognized_text": clean_text,
                    "raw_text": raw_text,
                    "processed_text": processed_text,
                    "emotion": emotion_info,
                    "events": event_info,
                    "language": language,
                    "engine": "FunAudioLLM-SenseVoice",
                    "confidence": result[0].get("confidence", 1.0)
                }
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_audio_path):
                    os.unlink(temp_audio_path)
            
        except Exception as e:
            logger.error(f"âŒ FunAudioLLMè¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "engine": "FunAudioLLM-SenseVoice",
                "recognized_text": ""
            }
    
    def _save_audio_temp(self, audio_data: bytes) -> str:
        """ä¿å­˜éŸ³é¢‘æ•°æ®åˆ°ä¸´æ—¶æ–‡ä»¶"""
        try:
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
            temp_file.write(audio_data)
            temp_file.close()
            return temp_file.name
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
            raise
    
    # ... å…¶ä»–æ–¹æ³•ä¿æŒä¸å˜
```

### 2. æ›´æ–°æœåŠ¡é…ç½®

ç¼–è¾‘ `backend/app/services/__init__.py`ï¼š

```python
# é€‰æ‹©ä½¿ç”¨çœŸå®æœåŠ¡è¿˜æ˜¯æ¨¡æ‹ŸæœåŠ¡
USE_REAL_FUNAUDIO = True  # è®¾ç½®ä¸º True ä½¿ç”¨çœŸå®æœåŠ¡

if USE_REAL_FUNAUDIO:
    from .funaudio_service import funaudio_service
else:
    from .funaudio_service_mock import funaudio_service
```

### 3. å®‰è£…éŸ³é¢‘å¤„ç†ä¾èµ–

```bash
# è¿›å…¥åç«¯ç›®å½•
cd backend

# å®‰è£…éŸ³é¢‘å¤„ç†åº“
pip install pydub
pip install scipy
pip install numpy

# ç³»ç»Ÿçº§éŸ³é¢‘å·¥å…· (Ubuntu/Debian)
sudo apt-get install ffmpeg libsndfile1

# macOS
brew install ffmpeg libsndfile

# Windows
# ä¸‹è½½ ffmpeg å¹¶æ·»åŠ åˆ° PATH
```

## ğŸš€ å¯åŠ¨é…ç½®

### 1. æ›´æ–° requirements.txt

```txt
# åœ¨ backend/requirements.txt ä¸­æ·»åŠ 
funasr>=1.0.0
modelscope>=1.9.0
soundfile>=0.12.1
librosa>=0.10.0
torch>=1.13.0
transformers>=4.30.0
accelerate>=0.20.0
```

### 2. ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `backend/.env` æ–‡ä»¶ï¼š

```env
# FunAudioLLM é…ç½®
FUNAUDIO_MODEL_PATH=iic/SenseVoiceSmall
FUNAUDIO_DEVICE=auto  # auto, cpu, cuda
FUNAUDIO_CACHE_DIR=./models/cache

# æ¨¡å‹ä¸‹è½½é…ç½®
HF_ENDPOINT=https://hf-mirror.com  # ä¸­å›½ç”¨æˆ·åŠ é€Ÿ
MODELSCOPE_CACHE=./models/modelscope
```

### 3. å¯åŠ¨æœåŠ¡

```bash
# å¯åŠ¨åç«¯æœåŠ¡
cd backend
python -m uvicorn app.main:app --reload --port 8000

# å¯åŠ¨å‰ç«¯æœåŠ¡
cd frontend
pnpm dev
```

## ğŸ” éªŒè¯å®‰è£…

### 1. æ£€æŸ¥æ¨¡å‹åŠ è½½

è®¿é—®ï¼š`http://localhost:8000/voice/engine`

åº”è¯¥çœ‹åˆ°ï¼š
```json
{
  "success": true,
  "engine": {
    "name": "FunAudioLLM",
    "status": {
      "available": true,
      "model_name": "FunAudioLLM-SenseVoice",
      "device": "cuda",
      "features": [
        "é«˜æ€§èƒ½è¯­éŸ³è¯†åˆ« (æ¯”Whisperå¿«15å€)",
        "æƒ…æ„Ÿè¯†åˆ«",
        "å£°å­¦äº‹ä»¶æ£€æµ‹",
        "50+è¯­è¨€æ”¯æŒ"
      ]
    }
  }
}
```

### 2. æµ‹è¯•è¯­éŸ³è¯†åˆ«

è®¿é—®ï¼š`http://localhost:3000/voice-funaudio`

ç°åœ¨åº”è¯¥èƒ½çœ‹åˆ°çœŸå®çš„è¯­éŸ³è¯†åˆ«ç»“æœï¼

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. GPU åŠ é€Ÿ

```python
# ç¡®ä¿ CUDA å¯ç”¨
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA device count: {torch.cuda.device_count()}")
```

### 2. æ¨¡å‹é‡åŒ–

```python
# åœ¨æ¨¡å‹åˆå§‹åŒ–æ—¶å¯ç”¨é‡åŒ–
self.model = AutoModel(
    model="iic/SenseVoiceSmall",
    trust_remote_code=True,
    device=self.device,
    # å¯ç”¨é‡åŒ–ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
    torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
)
```

### 3. æ‰¹å¤„ç†ä¼˜åŒ–

```python
# æ‰¹é‡å¤„ç†å¤šä¸ªéŸ³é¢‘æ–‡ä»¶
results = self.model.generate(
    input=[audio_path1, audio_path2, audio_path3],
    batch_size_s=60,
    # å…¶ä»–å‚æ•°...
)
```

## ğŸ› å¸¸è§é—®é¢˜

### 1. æ¨¡å‹ä¸‹è½½å¤±è´¥

```bash
# ä½¿ç”¨é•œåƒæº
export HF_ENDPOINT=https://hf-mirror.com
pip install funasr
```

### 2. CUDA å†…å­˜ä¸è¶³

```python
# å‡å°‘æ‰¹å¤„ç†å¤§å°
batch_size_s=30  # é»˜è®¤ 60

# ä½¿ç”¨ CPU
device="cpu"
```

### 3. éŸ³é¢‘æ ¼å¼ä¸æ”¯æŒ

```python
# å®‰è£…é¢å¤–çš„éŸ³é¢‘ç¼–è§£ç å™¨
pip install ffmpeg-python
sudo apt-get install libavcodec-extra
```

### 4. æƒé™é—®é¢˜

```bash
# ç¡®ä¿ä¸´æ—¶ç›®å½•å¯å†™
chmod 755 /tmp
```

## ğŸ“Š æ¨¡å‹é€‰æ‹©

### SenseVoice æ¨¡å‹å¯¹æ¯”

| æ¨¡å‹ | å¤§å° | é€Ÿåº¦ | ç²¾åº¦ | æ¨èåœºæ™¯ |
|------|------|------|------|----------|
| SenseVoiceSmall | ~500MB | æå¿« | é«˜ | å®æ—¶åº”ç”¨ |
| SenseVoiceLarge | ~1.5GB | å¿« | æé«˜ | ç¦»çº¿å¤„ç† |

### è¯­è¨€æ”¯æŒ

- **ä¸­æ–‡**: zh (æ™®é€šè¯)
- **è‹±æ–‡**: en
- **ç²¤è¯­**: yue
- **æ—¥è¯­**: ja
- **éŸ©è¯­**: ko
- **è‡ªåŠ¨æ£€æµ‹**: auto (æ¨è)

## ğŸ‰ å®Œæˆï¼

ç°åœ¨ä½ å·²ç»æˆåŠŸå®‰è£…å’Œé…ç½®äº†çœŸæ­£çš„ FunAudioLLM å’Œ SenseVoice æ¨¡å‹ï¼

è®¿é—® `http://localhost:3000/voice-funaudio` ä½“éªŒçœŸå®çš„é«˜æ€§èƒ½è¯­éŸ³è¯†åˆ«åŠŸèƒ½ã€‚

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœé‡åˆ°é—®é¢˜ï¼š

1. æŸ¥çœ‹åç«¯æ—¥å¿—ï¼š`tail -f backend/logs/app.log`
2. æ£€æŸ¥æ¨¡å‹çŠ¶æ€ï¼š`GET /api/voice/engine`
3. éªŒè¯ç¯å¢ƒï¼š`python -c "import funasr; print('FunASR installed successfully')"`

äº«å— 15 å€äº Whisper çš„è¯­éŸ³è¯†åˆ«é€Ÿåº¦å§ï¼ğŸš€ 