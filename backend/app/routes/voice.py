from fastapi import APIRouter, UploadFile, File, Form, HTTPException, Query, WebSocket, WebSocketDisconnect
from fastapi.responses import JSONResponse, StreamingResponse, Response
from typing import Optional, Dict, List, Any
import logging
from app.services.funaudio_service_real import FunAudioLLMService
from app.services.tts_service import tts_service
import json
import base64
import asyncio
import os
from pydantic import BaseModel
from app.services.lm_studio_service import lm_studio_service
from app.models.schemas import ChatRequest
from app.utils import clean_text_for_speech, split_text_for_tts, synthesize_speech_chunk
import re

# åˆ›å»º FunAudioLLM æœåŠ¡å®ä¾‹
funaudio_service = FunAudioLLMService()

router = APIRouter(prefix="/voice", tags=["voice"])

logger = logging.getLogger(__name__)

# WebSocketè¿æ¥ç®¡ç†å™¨
class VoiceConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []
        self.connection_configs: Dict[WebSocket, Dict] = {}
        self.connection_sessions: Dict[WebSocket, str] = {}
    
    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)
        # ä¸ºæ¯ä¸ªè¿æ¥ç”Ÿæˆå”¯ä¸€çš„ä¼šè¯ID
        session_id = f"ws-session-{len(self.active_connections)}-{asyncio.get_event_loop().time()}"
        self.connection_sessions[websocket] = session_id
        logger.info(f"ğŸ”Œ æ–°çš„è¯­éŸ³WebSocketè¿æ¥: {len(self.active_connections)}ä¸ªæ´»è·ƒè¿æ¥, ä¼šè¯ID: {session_id}")
    
    def disconnect(self, websocket: WebSocket):
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)
        if websocket in self.connection_configs:
            del self.connection_configs[websocket]
        if websocket in self.connection_sessions:
            del self.connection_sessions[websocket]
        logger.info(f"ğŸ”Œ è¯­éŸ³WebSocketè¿æ¥æ–­å¼€: {len(self.active_connections)}ä¸ªæ´»è·ƒè¿æ¥")
    
    def set_config(self, websocket: WebSocket, config: Dict):
        self.connection_configs[websocket] = config
    
    def get_config(self, websocket: WebSocket) -> Dict:
        return self.connection_configs.get(websocket, {})
    
    def get_session_id(self, websocket: WebSocket) -> str:
        return self.connection_sessions.get(websocket, "default")

voice_manager = VoiceConnectionManager()

# è¯­éŸ³åˆæˆè¯·æ±‚æ¨¡å‹
class SpeechSynthesizeRequest(BaseModel):
    text: str
    voice: Optional[str] = "zh-CN-XiaoxiaoNeural"
    rate: Optional[float] = 1.0
    pitch: Optional[float] = 1.0

@router.post("/chat")
async def voice_chat(
    audio: UploadFile = File(...),
    session_id: str = Form("default"),
    language: str = Form("auto")
):
    """
    è¯­éŸ³èŠå¤©æ¥å£ - ä½¿ç”¨FunAudioLLMè¿›è¡Œé«˜æ€§èƒ½è¯­éŸ³è¯†åˆ«å’Œå¯¹è¯
    
    ç‰¹æ€§:
    - é«˜æ€§èƒ½è¯­éŸ³è¯†åˆ«ï¼ˆæ¯”Whisperå¿«15å€ï¼‰
    - æƒ…æ„Ÿè¯†åˆ«å’Œå£°å­¦äº‹ä»¶æ£€æµ‹
    - æ”¯æŒ50+è¯­è¨€
    - å¯¹è¯å†å²ç®¡ç†
    """
    try:
        logger.info(f"ğŸ¤ FunAudioLLMè¯­éŸ³èŠå¤©è¯·æ±‚ - ä¼šè¯: {session_id}, è¯­è¨€: {language}")
        
        # è¯»å–éŸ³é¢‘æ•°æ®
        audio_data = await audio.read()
        
        if len(audio_data) == 0:
            raise HTTPException(status_code=400, detail="éŸ³é¢‘æ•°æ®ä¸ºç©º")
        
        # è°ƒç”¨FunAudioLLMæœåŠ¡è¿›è¡Œè¯­éŸ³èŠå¤©
        result = await funaudio_service.voice_chat(
            audio_data=audio_data,
            session_id=session_id,
            language=language
        )
        
        if result["success"]:
            logger.info(f"âœ… FunAudioLLMè¯­éŸ³èŠå¤©æˆåŠŸ - è¯†åˆ«: {result['recognized_text'][:50]}...")
            return JSONResponse(content=result)
        else:
            # æ£€æŸ¥æ˜¯å¦æ˜¯"æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³å†…å®¹"çš„æƒ…å†µ
            error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯')
            if "æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³å†…å®¹" in error_msg:
                logger.info(f"ğŸ”‡ æœªæ£€æµ‹åˆ°è¯­éŸ³å†…å®¹: {error_msg}")
                # è¿”å›200çŠ¶æ€ç ï¼Œä½†successä¸ºfalseï¼Œè¡¨ç¤ºæ­£å¸¸å¤„ç†ä½†æ²¡æœ‰è¯­éŸ³
                return JSONResponse(content=result)
            else:
                # çœŸæ­£çš„é”™è¯¯æ‰è¿”å›500
                logger.error(f"âŒ FunAudioLLMè¯­éŸ³èŠå¤©å¤±è´¥: {error_msg}")
                return JSONResponse(
                    status_code=500,
                    content=result
                )
            
    except Exception as e:
        logger.error(f"âŒ FunAudioLLMè¯­éŸ³èŠå¤©å¼‚å¸¸: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "recognized_text": "",
                "response": "æŠ±æ­‰ï¼Œè¯­éŸ³å¤„ç†å‡ºç°é—®é¢˜ã€‚è¯·ç¨åé‡è¯•ã€‚",
                "engine": "FunAudioLLM-SenseVoice"
            }
        )

@router.post("/recognize")
async def voice_recognize(
    audio: UploadFile = File(...),
    language: str = Form("auto")
):
    """FunAudioLLMè¯­éŸ³è¯†åˆ«"""
    try:
        logger.info(f"ğŸ¯ FunAudioLLMè¯­éŸ³è¯†åˆ«è¯·æ±‚ - è¯­è¨€: {language}")
        
        # è¯»å–éŸ³é¢‘æ•°æ®
        audio_data = await audio.read()
        
        if len(audio_data) == 0:
            raise HTTPException(status_code=400, detail="éŸ³é¢‘æ•°æ®ä¸ºç©º")
        
        # è°ƒç”¨FunAudioLLMæœåŠ¡è¿›è¡Œè¯­éŸ³è¯†åˆ«
        result = await funaudio_service.voice_recognition(
            audio_data=audio_data,
            language=language
        )
        
        if result["success"]:
            logger.info(f"âœ… FunAudioLLMè¯­éŸ³è¯†åˆ«æˆåŠŸ: {result['recognized_text'][:50]}...")
            return JSONResponse(content=result)
        else:
            logger.error(f"âŒ FunAudioLLMè¯­éŸ³è¯†åˆ«å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return JSONResponse(
                status_code=500,
                content=result
            )
            
    except Exception as e:
        logger.error(f"âŒ FunAudioLLMè¯­éŸ³è¯†åˆ«å¼‚å¸¸: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "recognized_text": "",
                "engine": "FunAudioLLM-SenseVoice"
            }
        )

@router.post("/analyze")
async def audio_analysis(
    audio: UploadFile = File(...),
    query: str = Form(...),
    session_id: str = Form("default")
):
    """
    éŸ³é¢‘åˆ†ææ¥å£ - åŸºäºFunAudioLLMçš„è¯­éŸ³è¯†åˆ«ç»“æœè¿›è¡Œåˆ†æ
    """
    try:
        logger.info(f"ğŸ” æ”¶åˆ°éŸ³é¢‘åˆ†æè¯·æ±‚")
        
        # è¯»å–éŸ³é¢‘æ•°æ®
        audio_data = await audio.read()
        
        if len(audio_data) == 0:
            raise HTTPException(status_code=400, detail="éŸ³é¢‘æ•°æ®ä¸ºç©º")
        
        if not query.strip():
            raise HTTPException(status_code=400, detail="æŸ¥è¯¢æ–‡æœ¬ä¸ºç©º")
        
        # ä½¿ç”¨FunAudioLLMè¿›è¡Œè¯­éŸ³è¯†åˆ«
        recognition_result = await funaudio_service.voice_recognition(audio_data, "auto")
        
        if recognition_result["success"]:
            result = {
                "success": True,
                "response": f"åŸºäºFunAudioLLMè¯†åˆ«ç»“æœï¼šã€Œ{recognition_result['recognized_text']}ã€\nåˆ†ææŸ¥è¯¢ï¼š{query}\næƒ…æ„Ÿä¿¡æ¯ï¼š{recognition_result.get('emotion', {})}",
                "query": query,
                "engine": "FunAudioLLM-SenseVoice",
                "analysis_type": "recognition_based_analysis",
                "recognition_result": recognition_result
            }
        else:
            result = recognition_result
        
        if result["success"]:
            logger.info(f"âœ… éŸ³é¢‘åˆ†ææˆåŠŸ")
            return JSONResponse(content=result)
        else:
            logger.error(f"âŒ éŸ³é¢‘åˆ†æå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return JSONResponse(
                status_code=500,
                content=result
            )
            
    except Exception as e:
        logger.error(f"âŒ éŸ³é¢‘åˆ†ææ¥å£é”™è¯¯: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e)
            }
        )

@router.get("/engine")
async def get_voice_engine_status():
    """è·å–FunAudioLLMå¼•æ“çŠ¶æ€"""
    try:
        logger.info("ğŸ” æ£€æŸ¥FunAudioLLMå¼•æ“çŠ¶æ€...")
        
        # è·å–æœåŠ¡å¥åº·çŠ¶æ€
        status = await funaudio_service.health_check()
        
        return JSONResponse(content={
            "success": True,
            "engine": {
                "name": "FunAudioLLM",
                "status": status,
                "features": status.get("features", []),
                "supported_languages": status.get("supported_languages", [])
            },
            "message": "FunAudioLLMå¼•æ“çŠ¶æ€æ£€æŸ¥å®Œæˆ"
        })
        
    except Exception as e:
        logger.error(f"âŒ FunAudioLLMå¼•æ“çŠ¶æ€æ£€æŸ¥å¤±è´¥: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "engine": {
                    "name": "FunAudioLLM",
                    "status": {"available": False}
                }
            }
        )

@router.get("/conversation/{session_id}")
async def get_conversation_summary(session_id: str):
    """è·å–ä¼šè¯æ‘˜è¦"""
    try:
        logger.info(f"ğŸ“Š è·å–FunAudioLLMä¼šè¯æ‘˜è¦: {session_id}")
        
        summary = await funaudio_service.get_conversation_summary(session_id)
        
        return JSONResponse(content={
            "success": True,
            "summary": summary
        })
        
    except Exception as e:
        logger.error(f"âŒ è·å–ä¼šè¯æ‘˜è¦å¤±è´¥: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e)
            }
        )

@router.delete("/conversation/{session_id}")
async def clear_conversation_history(session_id: str):
    """æ¸…é™¤ä¼šè¯å†å²"""
    try:
        logger.info(f"ğŸ—‘ï¸ æ¸…é™¤FunAudioLLMä¼šè¯å†å²: {session_id}")
        
        success = await funaudio_service.clear_conversation_history(session_id)
        
        if success:
            return JSONResponse(content={
                "success": True,
                "message": f"ä¼šè¯ {session_id} å†å²å·²æ¸…é™¤"
            })
        else:
            return JSONResponse(
                status_code=500,
                content={
                    "success": False,
                    "error": "æ¸…é™¤ä¼šè¯å†å²å¤±è´¥"
                }
            )
            
    except Exception as e:
        logger.error(f"âŒ æ¸…é™¤ä¼šè¯å†å²å¼‚å¸¸: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e)
            }
        )


@router.websocket("/ws/voice")
async def voice_websocket(websocket: WebSocket):
    """
    ç»Ÿä¸€è¯­éŸ³WebSocketç«¯ç‚¹
    
    æ”¯æŒå®æ—¶éŸ³é¢‘æµå¤„ç†ã€å”¤é†’è¯æ£€æµ‹å’Œè¯­éŸ³å¯¹è¯
    æ¶ˆæ¯æ ¼å¼:
    - é…ç½®: {"type": "config", "wake_words": [...], "confidence_threshold": 0.6, "session_id": "optional"}
    - éŸ³é¢‘: {"type": "audio", "data": "base64_audio_data", "timestamp": 1234567890, "mode": "wake_word|voice_chat"}
    - è¯­éŸ³å¯¹è¯: {"type": "voice_chat", "data": "base64_audio_data", "session_id": "optional", "language": "auto"}
    - çŠ¶æ€: {"type": "status", "status": "connected|listening|processing|error"}
    - å¿ƒè·³: {"type": "ping"} / {"type": "pong"}
    """
    await voice_manager.connect(websocket)
    
    try:
        # å‘é€è¿æ¥ç¡®è®¤
        await websocket.send_json({
            "type": "status",
            "status": "connected",
            "message": "è¯­éŸ³WebSocketè¿æ¥å·²å»ºç«‹",
            "session_id": voice_manager.get_session_id(websocket),
            "timestamp": asyncio.get_event_loop().time()
        })
        
        while True:
            # æ¥æ”¶æ¶ˆæ¯
            try:
                message = await websocket.receive_json()
                await handle_voice_message(websocket, message)
            except Exception as e:
                logger.error(f"âŒ å¤„ç†WebSocketæ¶ˆæ¯å¤±è´¥: {e}")
                await websocket.send_json({
                    "type": "error",
                    "error": str(e),
                    "timestamp": asyncio.get_event_loop().time()
                })
                
    except WebSocketDisconnect:
        logger.info("ğŸ”Œ è¯­éŸ³WebSocketå®¢æˆ·ç«¯æ–­å¼€è¿æ¥")
    except Exception as e:
        logger.error(f"âŒ è¯­éŸ³WebSocketè¿æ¥å¼‚å¸¸: {e}")
    finally:
        voice_manager.disconnect(websocket)



async def handle_voice_message(websocket: WebSocket, message: Dict):
    """å¤„ç†ç»Ÿä¸€è¯­éŸ³WebSocketæ¶ˆæ¯"""
    message_type = message.get("type")
    
    if message_type == "config":
        # é…ç½®æ¶ˆæ¯
        config = {
            "wake_words": message.get("wake_words", ["å°æ™ºå°æ™º", "å°æ™º", "æ™ºèƒ½åŠ©æ‰‹"]),
            "confidence_threshold": message.get("confidence_threshold", 0.6),
            "language": message.get("language", "zh"),
            "session_id": message.get("session_id") or voice_manager.get_session_id(websocket)
        }
        voice_manager.set_config(websocket, config)
        
        await websocket.send_json({
            "type": "config_ack",
            "config": config,
            "message": "é…ç½®å·²æ›´æ–°",
            "timestamp": asyncio.get_event_loop().time()
        })
        
    elif message_type == "audio":
        # éŸ³é¢‘æ•°æ®æ¶ˆæ¯ - æ ¹æ®modeå†³å®šå¤„ç†æ–¹å¼
        mode = message.get("mode", "wake_word")
        if mode == "wake_word":
            await process_wake_word_audio(websocket, message)
        elif mode == "voice_chat":
            await process_voice_chat_audio(websocket, message)
        else:
            await websocket.send_json({
                "type": "error",
                "error": f"æœªçŸ¥éŸ³é¢‘æ¨¡å¼: {mode}",
                "timestamp": asyncio.get_event_loop().time()
            })
        
    elif message_type == "voice_chat":
        # è¯­éŸ³å¯¹è¯æ¶ˆæ¯
        await process_voice_chat_audio(websocket, message)
        
    elif message_type == "ping":
        # å¿ƒè·³æ¶ˆæ¯
        await websocket.send_json({
            "type": "pong",
            "timestamp": asyncio.get_event_loop().time()
        })
        
    else:
        await websocket.send_json({
            "type": "error",
            "error": f"æœªçŸ¥æ¶ˆæ¯ç±»å‹: {message_type}",
            "timestamp": asyncio.get_event_loop().time()
        })

# ä¿æŒå‘åå…¼å®¹æ€§
async def handle_wake_word_message(websocket: WebSocket, message: Dict):
    """å‘åå…¼å®¹çš„å”¤é†’è¯æ¶ˆæ¯å¤„ç†"""
    await handle_voice_message(websocket, message)

async def process_wake_word_audio(websocket: WebSocket, message: Dict):
    """å¤„ç†éŸ³é¢‘æ•°æ®è¿›è¡Œå”¤é†’è¯æ£€æµ‹"""
    try:
        # è·å–é…ç½®
        config = voice_manager.get_config(websocket)
        if not config:
            await websocket.send_json({
                "type": "error",
                "error": "è¯·å…ˆå‘é€é…ç½®ä¿¡æ¯",
                "timestamp": asyncio.get_event_loop().time()
            })
            return
        
        # å‘é€å¤„ç†çŠ¶æ€
        await websocket.send_json({
            "type": "status",
            "status": "processing",
            "timestamp": asyncio.get_event_loop().time()
        })
        
        # è§£ç éŸ³é¢‘æ•°æ®
        audio_data_b64 = message.get("data")
        if not audio_data_b64:
            raise ValueError("éŸ³é¢‘æ•°æ®ä¸ºç©º")
        
        audio_data = base64.b64decode(audio_data_b64)
        
        if len(audio_data) == 0:
            raise ValueError("éŸ³é¢‘æ•°æ®è§£ç åä¸ºç©º")
        
        # è°ƒç”¨FunAudioLLMè¿›è¡Œå”¤é†’è¯æ£€æµ‹
        result = await funaudio_service.wake_word_detection(
            audio_data=audio_data,
            wake_words=config["wake_words"]
        )
        
        # å‘é€æ£€æµ‹ç»“æœ
        response = {
            "type": "detection",
            "wake_word_detected": result["wake_word_detected"],
            "detected_word": result.get("detected_word", ""),
            "recognized_text": result.get("recognized_text", ""),
            "confidence": result.get("confidence", 0.0),
            "engine": result.get("engine", "FunAudioLLM-SenseVoice"),
            "timestamp": asyncio.get_event_loop().time(),
            "success": result["success"]
        }
        
        if result["wake_word_detected"]:
            logger.info(f"âœ… WebSocketæ£€æµ‹åˆ°å”¤é†’è¯: {result['detected_word']}")
        
        await websocket.send_json(response)
        
        # å‘é€ç›‘å¬çŠ¶æ€
        await websocket.send_json({
            "type": "status",
            "status": "listening",
            "timestamp": asyncio.get_event_loop().time()
        })
        
    except Exception as e:
        logger.error(f"âŒ WebSocketéŸ³é¢‘å¤„ç†å¤±è´¥: {e}")
        await websocket.send_json({
            "type": "error",
            "error": str(e),
            "timestamp": asyncio.get_event_loop().time()
        })

async def process_voice_chat_audio(websocket: WebSocket, message: Dict):
    """å¤„ç†éŸ³é¢‘æ•°æ®è¿›è¡Œè¯­éŸ³å¯¹è¯"""
    try:
        # è·å–é…ç½®
        config = voice_manager.get_config(websocket)
        session_id = message.get("session_id") or voice_manager.get_session_id(websocket)
        language = message.get("language", config.get("language", "auto"))
        
        # å‘é€å¤„ç†çŠ¶æ€
        await websocket.send_json({
            "type": "status",
            "status": "processing",
            "message": "æ­£åœ¨å¤„ç†è¯­éŸ³å¯¹è¯",
            "timestamp": asyncio.get_event_loop().time()
        })
        
        # è§£ç éŸ³é¢‘æ•°æ®
        audio_data_b64 = message.get("data")
        if not audio_data_b64:
            raise ValueError("éŸ³é¢‘æ•°æ®ä¸ºç©º")
        
        audio_data = base64.b64decode(audio_data_b64)
        
        if len(audio_data) == 0:
            raise ValueError("éŸ³é¢‘æ•°æ®è§£ç åä¸ºç©º")
        
        # è°ƒç”¨FunAudioLLMè¿›è¡Œè¯­éŸ³å¯¹è¯
        result = await funaudio_service.voice_chat(
            audio_data=audio_data,
            session_id=session_id,
            language=language
        )
        
        # å‘é€å¯¹è¯ç»“æœ
        response = {
            "type": "voice_chat_response",
            "success": result["success"],
            "recognized_text": result.get("recognized_text", ""),
            "response": result.get("response", ""),
            "session_id": session_id,
            "history_length": result.get("history_length", 0),
            "engine": result.get("engine", "FunAudioLLM-SenseVoice"),
            "emotion": result.get("emotion", {}),
            "timestamp": asyncio.get_event_loop().time()
        }
        
        if result["success"]:
            logger.info(f"âœ… WebSocketè¯­éŸ³å¯¹è¯æˆåŠŸ: {result.get('recognized_text', '')[:50]}...")
        else:
            logger.warning(f"âš ï¸ WebSocketè¯­éŸ³å¯¹è¯å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            response["error"] = result.get("error", "è¯­éŸ³å¯¹è¯å¤„ç†å¤±è´¥")
        
        await websocket.send_json(response)
        
        # å‘é€ç›‘å¬çŠ¶æ€
        await websocket.send_json({
            "type": "status",
            "status": "listening",
            "message": "ç­‰å¾…ä¸‹ä¸€æ¬¡è¯­éŸ³è¾“å…¥",
            "timestamp": asyncio.get_event_loop().time()
        })
        
    except Exception as e:
        logger.error(f"âŒ WebSocketè¯­éŸ³å¯¹è¯å¤„ç†å¤±è´¥: {e}")
        await websocket.send_json({
            "type": "error",
            "error": str(e),
            "timestamp": asyncio.get_event_loop().time()
        })

@router.post("/speech/synthesize")
async def speech_synthesize(request: SpeechSynthesizeRequest):
    """
    è¯­éŸ³åˆæˆç«¯ç‚¹ - ç›´æ¥è¿”å›éŸ³é¢‘æµ
    
    ä¸/ttsç«¯ç‚¹ä¸åŒï¼Œæ­¤ç«¯ç‚¹ç›´æ¥è¿”å›éŸ³é¢‘æ–‡ä»¶å†…å®¹ï¼Œè€Œä¸æ˜¯æ–‡ä»¶ä¿¡æ¯
    ä¸“ä¸ºå‰ç«¯/speech/synthesizeè·¯ç”±è®¾è®¡
    """
    try:
        logger.info(f"ğŸ”Š è¯­éŸ³åˆæˆè¯·æ±‚: {request.text[:50]}...")
        
        # æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤æ€è€ƒæ ‡ç­¾å’Œè¡¨æƒ…ç¬¦å·
        clean_text = clean_text_for_speech(request.text)
        
        if not clean_text.strip():
            logger.warning("æ¸…ç†åçš„æ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡è¯­éŸ³åˆæˆ")
            # è¿”å›ç©ºçš„éŸ³é¢‘å“åº”
            return Response(
                content=b"",
                media_type="audio/mpeg",
                headers={
                    "Content-Length": "0",
                    "Content-Disposition": "inline; filename=empty_speech.mp3"
                }
            )
        
        # è½¬æ¢å‚æ•°æ ¼å¼ä»¥åŒ¹é…TTSæœåŠ¡
        rate_str = f"+{int((request.rate - 1) * 100)}%" if request.rate >= 1 else f"{int((request.rate - 1) * 100)}%"
        
        # è°ƒç”¨TTSæœåŠ¡ï¼Œä½¿ç”¨æ¸…ç†åçš„æ–‡æœ¬
        audio_path, file_size = await tts_service.text_to_speech(
            text=clean_text,
            voice=request.voice,
            rate=rate_str,
            volume="+0%"  # pitchåœ¨edge-ttsä¸­å¯¹åº”volumeå‚æ•°
        )
        
        # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(audio_path):
            raise HTTPException(status_code=500, detail="éŸ³é¢‘æ–‡ä»¶ç”Ÿæˆå¤±è´¥")
        
        # è¯»å–éŸ³é¢‘æ–‡ä»¶å†…å®¹
        with open(audio_path, "rb") as audio_file:
            audio_content = audio_file.read()
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            os.remove(audio_path)
        except Exception as e:
            logger.warning(f"æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
        
        logger.info(f"âœ… è¯­éŸ³åˆæˆæˆåŠŸï¼Œæ–‡ä»¶å¤§å°: {len(audio_content)} å­—èŠ‚")
        
        # ç›´æ¥è¿”å›éŸ³é¢‘å†…å®¹
        return Response(
            content=audio_content,
            media_type="audio/mpeg",
            headers={
                "Content-Length": str(len(audio_content)),
                "Content-Disposition": "inline; filename=synthesized_speech.mp3"
            }
        )
        
    except Exception as e:
        logger.error(f"âŒ è¯­éŸ³åˆæˆå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è¯­éŸ³åˆæˆå¤±è´¥: {str(e)}")

@router.post("/chat/stream")
async def voice_chat_stream(
    audio: UploadFile = File(...),
    session_id: str = Form(...),
    language: str = Form(default="auto"),
    knowledge_base_id: Optional[str] = Form(default=None)
):
    """æµå¼è¯­éŸ³èŠå¤© - AIç”Ÿæˆå›å¤çš„åŒæ—¶è¿›è¡ŒTTSåˆæˆ"""
    try:
        logger.info(f"ğŸ¤ å¼€å§‹æµå¼è¯­éŸ³èŠå¤©å¤„ç†ï¼Œä¼šè¯ID: {session_id}")
        
        # è¯»å–éŸ³é¢‘æ•°æ®
        audio_data = await audio.read()
        if len(audio_data) == 0:
            raise HTTPException(status_code=400, detail="éŸ³é¢‘æ•°æ®ä¸ºç©º")

        async def generate_streaming_response():
            try:
                # ç¬¬ä¸€æ­¥ï¼šè¯­éŸ³è¯†åˆ«
                yield f"data: {json.dumps({'type': 'status', 'message': 'æ­£åœ¨è¯†åˆ«è¯­éŸ³...'})}\n\n"
                
                # ä½¿ç”¨FunAudioLLMè¿›è¡Œè¯­éŸ³è¯†åˆ«
                recognition_result = await funaudio_service.voice_recognition(audio_data, language)
                
                if not recognition_result["success"]:
                    yield f"data: {json.dumps({'type': 'error', 'message': 'è¯­éŸ³è¯†åˆ«å¤±è´¥'})}\n\n"
                    return
                
                recognized_text = recognition_result["recognized_text"]
                
                if not recognized_text.strip():
                    yield f"data: {json.dumps({'type': 'error', 'message': 'æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³å†…å®¹'})}\n\n"
                    return
                
                # å‘é€è¯†åˆ«ç»“æœ
                yield f"data: {json.dumps({'type': 'recognition', 'text': recognized_text})}\n\n"
                
                # ç¬¬äºŒæ­¥ï¼šå‡†å¤‡AIèŠå¤©è¯·æ±‚
                yield f"data: {json.dumps({'type': 'status', 'message': 'AIæ­£åœ¨æ€è€ƒ...'})}\n\n"
                
                chat_request = ChatRequest(
                    message=recognized_text,
                    history=[],  # å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ å†å²è®°å½•
                    temperature=0.7,
                    max_tokens=2048,
                    stream=True
                )
                
                # ç¬¬ä¸‰æ­¥ï¼šæµå¼AIå¯¹è¯ + å®æ—¶TTS
                text_buffer = ""
                chunk_counter = 0
                
                async for ai_chunk in lm_studio_service.chat_completion_stream(chat_request):
                    if ai_chunk.strip():
                        text_buffer += ai_chunk
                        
                        # å‘é€AIç”Ÿæˆçš„æ–‡å­—ç‰‡æ®µ
                        yield f"data: {json.dumps({'type': 'ai_text', 'content': ai_chunk})}\n\n"
                        
                        # åœ¨è¿›è¡ŒTTSåˆ†å—å‰ï¼Œå…ˆæ¸…ç†æ€è€ƒæ ‡ç­¾
                        # è¿™æ˜¯é¢å¤–çš„å®‰å…¨æªæ–½ï¼Œç¡®ä¿æ€è€ƒæ ‡ç­¾ä¸ä¼šè¿›å…¥TTSç³»ç»Ÿ
                        cleaned_buffer = clean_text_for_speech(text_buffer)
                        
                        # æ£€æŸ¥æ˜¯å¦å¯ä»¥è¿›è¡ŒTTSåˆ†å—
                        chunks_to_synthesize = split_text_for_tts(cleaned_buffer)
                        
                        if chunks_to_synthesize:
                            # å¯¹æ¯ä¸ªå®Œæ•´çš„æ–‡æœ¬å—è¿›è¡ŒTTS
                            for chunk_text in chunks_to_synthesize:
                                try:
                                    # å†æ¬¡ç¡®ä¿æ–‡æœ¬æ¸…ç†ï¼ˆåŒé‡ä¿é™©ï¼‰
                                    final_clean_text = clean_text_for_speech(chunk_text)
                                    
                                    if not final_clean_text.strip():
                                        logger.info("è·³è¿‡ç©ºçš„æ–‡æœ¬å—")
                                        # ä»åŸå§‹ç¼“å†²åŒºç§»é™¤å·²å¤„ç†çš„æ–‡æœ¬
                                        text_buffer = text_buffer.replace(chunk_text, "", 1).strip()
                                        continue
                                    
                                    # TTSåˆæˆ
                                    audio_buffer = await synthesize_speech_chunk(final_clean_text)
                                    if audio_buffer:
                                        # å°†éŸ³é¢‘æ•°æ®ç¼–ç ä¸ºbase64
                                        audio_base64 = base64.b64encode(audio_buffer).decode('utf-8')
                                        
                                        # å‘é€éŸ³é¢‘æ•°æ®
                                        yield f"data: {json.dumps({'type': 'audio_chunk', 'audio': audio_base64, 'text': final_clean_text, 'chunk_id': chunk_counter})}\n\n"
                                        chunk_counter += 1
                                        
                                        logger.info(f"âœ… éŸ³é¢‘å— {chunk_counter-1} å‘é€æˆåŠŸ: {len(audio_buffer)} å­—èŠ‚")
                                    else:
                                        logger.info(f"âš ï¸ éŸ³é¢‘å—TTSè·³è¿‡: {repr(final_clean_text[:50])}")
                                        # å³ä½¿TTSå¤±è´¥ï¼Œä¹Ÿå‘é€ä¸€ä¸ªçŠ¶æ€æ¶ˆæ¯
                                        yield f"data: {json.dumps({'type': 'tts_skip', 'message': 'è·³è¿‡æ— æ•ˆæ–‡æœ¬å—', 'text': final_clean_text})}\n\n"
                                    
                                    # ä»åŸå§‹ç¼“å†²åŒºç§»é™¤å·²å¤„ç†çš„æ–‡æœ¬
                                    # ä½¿ç”¨åŸå§‹chunk_textè¿›è¡Œç§»é™¤ï¼Œä¿æŒç¼“å†²åŒºçŠ¶æ€æ­£ç¡®
                                    text_buffer = text_buffer.replace(chunk_text, "", 1).strip()
                                        
                                except Exception as e:
                                    logger.error(f"âŒ TTSåˆæˆå¼‚å¸¸: {e}, æ–‡æœ¬: {repr(chunk_text[:100])}")
                                    yield f"data: {json.dumps({'type': 'tts_error', 'message': f'è¯­éŸ³åˆæˆå¤±è´¥: {str(e)}', 'text': chunk_text[:100]})}\n\n"
                                    # å³ä½¿å‡ºé”™ï¼Œä¹Ÿè¦ç§»é™¤å·²å¤„ç†çš„æ–‡æœ¬ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªå—
                                    text_buffer = text_buffer.replace(chunk_text, "", 1).strip()
                
                # å¤„ç†å‰©ä½™çš„æ–‡æœ¬ç¼“å†²åŒº
                if text_buffer.strip():
                    try:
                        # æ¸…ç†å‰©ä½™æ–‡æœ¬
                        final_clean_text = clean_text_for_speech(text_buffer)
                        
                        if final_clean_text.strip():
                            logger.info(f"ğŸ”š å¤„ç†å‰©ä½™æ–‡æœ¬: {repr(final_clean_text[:100])}")
                            audio_buffer = await synthesize_speech_chunk(final_clean_text)
                            if audio_buffer:
                                audio_base64 = base64.b64encode(audio_buffer).decode('utf-8')
                                yield f"data: {json.dumps({'type': 'audio_chunk', 'audio': audio_base64, 'text': final_clean_text, 'chunk_id': chunk_counter})}\n\n"
                                logger.info(f"âœ… æœ€ç»ˆéŸ³é¢‘å—å‘é€æˆåŠŸ: {len(audio_buffer)} å­—èŠ‚")
                            else:
                                logger.info(f"âš ï¸ æœ€ç»ˆæ–‡æœ¬å—TTSè·³è¿‡: {repr(final_clean_text[:50])}")
                                yield f"data: {json.dumps({'type': 'tts_skip', 'message': 'è·³è¿‡æœ€ç»ˆæ— æ•ˆæ–‡æœ¬å—', 'text': final_clean_text})}\n\n"
                        else:
                            logger.info("å‰©ä½™æ–‡æœ¬æ¸…ç†åä¸ºç©ºï¼Œè·³è¿‡TTSåˆæˆ")
                    except Exception as e:
                        logger.error(f"âŒ æœ€ç»ˆTTSåˆæˆå¤±è´¥: {e}, åŸå§‹æ–‡æœ¬: {repr(text_buffer[:200])}")
                        yield f"data: {json.dumps({'type': 'tts_error', 'message': f'æœ€ç»ˆè¯­éŸ³åˆæˆå¤±è´¥: {str(e)}', 'text': text_buffer[:100]})}\n\n"
                
                # å‘é€å®Œæˆä¿¡å·
                yield f"data: {json.dumps({'type': 'complete'})}\n\n"
                yield "data: [DONE]\n\n"
                
            except Exception as e:
                logger.error(f"æµå¼è¯­éŸ³èŠå¤©å¤„ç†å¤±è´¥: {e}")
                yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
        
        return StreamingResponse(
            generate_streaming_response(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )
        
    except Exception as e:
        logger.error(f"æµå¼è¯­éŸ³èŠå¤©è¯·æ±‚å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¤„ç†è¯·æ±‚å¤±è´¥: {str(e)}")