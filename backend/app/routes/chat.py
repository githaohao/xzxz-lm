from fastapi import APIRouter, HTTPException, UploadFile, File, Form, Depends
from fastapi.responses import StreamingResponse, FileResponse
import uuid
import os
import time
from datetime import datetime
from typing import List, Optional
import aiofiles
import logging
import traceback
import json

from app.models.schemas import (
    ChatRequest, ChatResponse, FileUploadResponse, 
    OCRRequest, OCRResponse, TTSRequest, TTSResponse,
    MessageType, MultimodalStreamRequest, RAGSearchRequest, 
    RAGSearchResponse, DocumentInfo
)
from app.services.lm_studio_service import lm_studio_service
from app.services.ocr_service import ocr_service
from app.services.tts_service import tts_service
from app.services.rag_service import rag_service
from app.config import settings

logger = logging.getLogger(__name__)
router = APIRouter(prefix="", tags=["chat"])

@router.post("/chat", response_model=ChatResponse)
async def chat_completion(request: ChatRequest):
    """å¤„ç†èŠå¤©è¯·æ±‚"""
    try:
        start_time = time.time()
        
        # è°ƒç”¨LM StudioæœåŠ¡
        response_text = await lm_studio_service.chat_completion(request)
        
        processing_time = time.time() - start_time
        message_id = str(uuid.uuid4())
        
        return ChatResponse(
            response=response_text,
            message_id=message_id,
            processing_time=processing_time
        )
        
    except Exception as e:
        logger.error(f"èŠå¤©è¯·æ±‚å¤„ç†å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¤„ç†è¯·æ±‚å¤±è´¥: {str(e)}")

@router.post("/chat/stream")
async def chat_completion_stream(request: ChatRequest):
    """æµå¼èŠå¤©å“åº”"""
    try:
        async def generate():
            async for chunk in lm_studio_service.chat_completion_stream(request):
                if chunk.strip():
                    yield f"data: {json.dumps({'type': 'content', 'content': chunk})}\n\n"
            yield f"data: {json.dumps({'type': 'complete'})}\n\n"
            yield "data: [DONE]\n\n"
        
        return StreamingResponse(
            generate(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )
        
    except Exception as e:
        logger.error(f"æµå¼èŠå¤©è¯·æ±‚å¤„ç†å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¤„ç†è¯·æ±‚å¤±è´¥: {str(e)}")

@router.post("/upload", response_model=FileUploadResponse)
async def upload_file(file: UploadFile = File(...)):
    """æ–‡ä»¶ä¸Šä¼ å¤„ç†"""
    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        file_ext = os.path.splitext(file.filename)[1].lower()
        if file_ext not in settings.allowed_file_types:
            raise HTTPException(
                status_code=400,
                detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}"
            )
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        content = await file.read()
        if len(content) > settings.max_file_size:
            raise HTTPException(
                status_code=400,
                detail=f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶: {settings.max_file_size / 1024 / 1024:.1f}MB"
            )
        
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        file_id = str(uuid.uuid4())
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_filename = f"{timestamp}_{file_id}_{file.filename}"
        file_path = os.path.join(settings.upload_dir, safe_filename)
        
        # ä¿å­˜æ–‡ä»¶
        async with aiofiles.open(file_path, 'wb') as f:
            await f.write(content)
        
        logger.info(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {safe_filename}")
        
        return FileUploadResponse(
            file_id=file_id,
            file_name=file.filename,
            file_path=file_path,
            file_size=len(content),
            file_type=file_ext
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")

@router.post("/ocr", response_model=OCRResponse)
async def extract_text(file_path: str = Form(...)):
    """OCRæ–‡æœ¬æå–"""
    try:
        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
        
        file_ext = os.path.splitext(file_path)[1].lower()
        
        if file_ext == '.pdf':
            text, confidence, processing_time = await ocr_service.extract_text_from_pdf(file_path)
        elif file_ext in ['.png', '.jpg', '.jpeg']:
            text, confidence, processing_time = await ocr_service.extract_text_from_image(file_path)
        else:
            raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹è¿›è¡ŒOCR")
        
        return OCRResponse(
            text=text,
            confidence=confidence,
            processing_time=processing_time,
            detected_language="zh-cn" if confidence > 0 else None
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"OCRå¤„ç†å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"OCRå¤„ç†å¤±è´¥: {str(e)}")

@router.post("/tts", response_model=TTSResponse)
async def text_to_speech(request: TTSRequest):
    """æ–‡å­—è½¬è¯­éŸ³"""
    try:
        audio_path, file_size = await tts_service.text_to_speech(
            text=request.text,
            voice=request.voice,
            rate=request.rate,
            volume=request.volume
        )
        
        return TTSResponse(
            audio_file=os.path.basename(audio_path),
            file_size=file_size
        )
        
    except Exception as e:
        logger.error(f"TTSè½¬æ¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"TTSè½¬æ¢å¤±è´¥: {str(e)}")

@router.get("/tts/audio/{filename}")
async def get_tts_audio(filename: str):
    """è·å–TTSéŸ³é¢‘æ–‡ä»¶"""
    try:
        audio_path = os.path.join(settings.upload_dir, "tts_audio", filename)
        
        if not os.path.exists(audio_path):
            raise HTTPException(status_code=404, detail="éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        
        return FileResponse(
            audio_path,
            media_type="audio/mpeg",
            filename=filename
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {str(e)}")

# æ–°å¢ï¼šå¤„ç†å·²é¢„å¤„ç†æ–‡ä»¶æ•°æ®çš„æµå¼èŠå¤©æ¥å£
@router.post("/chat/multimodal/stream/processed")
async def multimodal_chat_stream_with_processed_data(
    request: MultimodalStreamRequest
):
    """å¤„ç†å·²é¢„å¤„ç†æ–‡ä»¶æ•°æ®çš„æµå¼å¤šæ¨¡æ€èŠå¤©æ¥å£"""
    async def generate():
        try:
            logger.info(f"å¼€å§‹å¤„ç†æµå¼å¤šæ¨¡æ€èŠå¤©è¯·æ±‚: {request.message[:50]}...")
            
            # æ„å»ºå®Œæ•´æ¶ˆæ¯
            full_message = request.message
            
            # å¦‚æœæœ‰æ–‡ä»¶æ•°æ®ï¼Œæ ¹æ®rag_enabledå†³å®šå¤„ç†æ–¹å¼
            if request.file_data:
                logger.info(f"å¤„ç†æ–‡ä»¶æ•°æ®: {request.file_data.name}")
                
                # æ£€æŸ¥æ˜¯å¦å¯ç”¨RAGåŠŸèƒ½
                if request.file_data.rag_enabled:
                    logger.info("å¯ç”¨RAGæ¨¡å¼ï¼Œè¿›è¡Œæ™ºèƒ½æ£€ç´¢...")
                    yield f"data: {json.dumps({'type': 'file_processing', 'message': 'ğŸ§  å¯ç”¨æ™ºèƒ½æ£€ç´¢æ¨¡å¼'})}\n\n"
                    
                    # å¦‚æœæ–‡ä»¶è¿˜æ²¡æœ‰è¿›è¡ŒRAGå¤„ç†ï¼Œå…ˆè¿›è¡Œå¤„ç†
                    if not request.file_data.doc_id and request.file_data.content:
                        logger.info("å¼€å§‹RAGæ–‡æ¡£å¤„ç†...")
                        yield f"data: {json.dumps({'type': 'file_processing', 'message': 'æ­£åœ¨å¯¹æ–‡æ¡£è¿›è¡Œæ™ºèƒ½ç´¢å¼•...'})}\n\n"
                        
                        # å¤„ç†æ–‡æ¡£å¹¶ç”Ÿæˆdoc_id
                        doc_id = await rag_service.process_document(
                            content=request.file_data.content,
                            filename=request.file_data.name,
                            file_type=request.file_data.type
                        )
                        request.file_data.doc_id = doc_id
                        yield f"data: {json.dumps({'type': 'file_processing', 'message': f'æ–‡æ¡£ç´¢å¼•å®Œæˆ: {request.file_data.name}'})}\n\n"
                    
                    # å¦‚æœæœ‰doc_idï¼Œä½¿ç”¨RAGæ£€ç´¢ç›¸å…³å†…å®¹
                    if request.file_data.doc_id:
                        logger.info("å¼€å§‹RAGæ£€ç´¢ç›¸å…³å†…å®¹...")
                        yield f"data: {json.dumps({'type': 'file_processing', 'message': 'æ­£åœ¨æ£€ç´¢ç›¸å…³æ–‡æ¡£ç‰‡æ®µ...'})}\n\n"
                        
                        relevant_chunks = await rag_service.search_relevant_chunks(
                            query=request.message,
                            doc_ids=[request.file_data.doc_id],
                            top_k=settings.rag_default_top_k,
                            min_similarity=settings.rag_default_min_similarity
                        )
                        
                        if relevant_chunks:
                            # æ„å»ºRAGä¸Šä¸‹æ–‡
                            rag_context = "\n\n[ç›¸å…³æ–‡æ¡£å†…å®¹]\n"
                            for i, chunk in enumerate(relevant_chunks, 1):
                                rag_context += f"ç‰‡æ®µ{i} (ç›¸ä¼¼åº¦: {chunk['similarity']:.2f}):\n{chunk['content']}\n\n"
                            
                            full_message = request.message + rag_context
                            chunk_count = len(relevant_chunks)
                            yield f"data: {json.dumps({'type': 'file_processing', 'message': f'ğŸ” æ£€ç´¢åˆ° {chunk_count} ä¸ªç›¸å…³ç‰‡æ®µ'})}\n\n"
                        else:
                            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›¸å…³å†…å®¹ï¼Œæç¤ºæ— ç›¸å…³å†…å®¹
                            yield f"data: {json.dumps({'type': 'file_processing', 'message': 'âš ï¸ æœªæ‰¾åˆ°ç›¸å…³ç‰‡æ®µ'})}\n\n"
                    else:
                        # æ²¡æœ‰doc_idä¸”æ²¡æœ‰contentï¼Œæ— æ³•å¤„ç†
                        yield f"data: {json.dumps({'type': 'file_processing', 'message': 'âŒ æ–‡æ¡£å¤„ç†å¤±è´¥ï¼šç¼ºå°‘å†…å®¹'})}\n\n"
                else:
                    # å…³é—­RAGæ¨¡å¼ï¼Œä½¿ç”¨å®Œæ•´æ–‡æ¡£å†…å®¹
                    logger.info("å…³é—­RAGæ¨¡å¼ï¼Œä½¿ç”¨å®Œæ•´æ–‡æ¡£å†…å®¹...")
                    yield f"data: {json.dumps({'type': 'file_processing', 'message': 'ğŸ“„ ä½¿ç”¨å®Œæ•´æ–‡æ¡£æ¨¡å¼'})}\n\n"
                    
                    if request.file_data.content:
                        # å¦‚æœæœ‰ç›´æ¥çš„å†…å®¹ï¼Œä½¿ç”¨å®ƒ
                        file_content = f"\n\n[æ–‡ä»¶å†…å®¹: {request.file_data.name}]\n{request.file_data.content}"
                        full_message = request.message + file_content
                        yield f"data: {json.dumps({'type': 'file_processing', 'message': f'å·²åŠ è½½å®Œæ•´æ–‡æ¡£: {request.file_data.name}'})}\n\n"
                    elif request.file_data.doc_id:
                        # å¦‚æœåªæœ‰doc_idï¼Œä»RAGç³»ç»Ÿè·å–æ‰€æœ‰åˆ†å—å†…å®¹
                        logger.info("ä»RAGç³»ç»Ÿè·å–å®Œæ•´æ–‡æ¡£å†…å®¹...")
                        yield f"data: {json.dumps({'type': 'file_processing', 'message': 'æ­£åœ¨è·å–å®Œæ•´æ–‡æ¡£å†…å®¹...'})}\n\n"
                        
                        # è·å–æ‰€æœ‰æ–‡æ¡£åˆ†å—
                        all_chunks = await rag_service.get_document_chunks(request.file_data.doc_id)
                        
                        if all_chunks:
                            # é‡å»ºå®Œæ•´æ–‡æ¡£ï¼ˆåˆ†å—å·²ç»æ’åºï¼‰
                            full_content = "\n".join([chunk['content'] for chunk in all_chunks])
                            
                            file_content = f"\n\n[æ–‡ä»¶å†…å®¹: {request.file_data.name}]\n{full_content}"
                            full_message = request.message + file_content
                            yield f"data: {json.dumps({'type': 'file_processing', 'message': f'å·²é‡å»ºå®Œæ•´æ–‡æ¡£: {request.file_data.name}'})}\n\n"
                        else:
                            yield f"data: {json.dumps({'type': 'file_processing', 'message': 'âŒ æ— æ³•è·å–æ–‡æ¡£å†…å®¹'})}\n\n"
                    else:
                        yield f"data: {json.dumps({'type': 'file_processing', 'message': 'âŒ æ–‡æ¡£å¤„ç†å¤±è´¥ï¼šç¼ºå°‘å†…å®¹å’ŒID'})}\n\n"
            

            
            # æ„å»ºèŠå¤©è¯·æ±‚
            chat_request = ChatRequest(
                message=full_message,
                history=request.history,
                temperature=request.temperature,
                max_tokens=request.max_tokens,
                stream=True
            )
            
            logger.info("å¼€å§‹AIæµå¼å¯¹è¯å¤„ç†...")
            
            # æµå¼è·å–AIå“åº”
            async for chunk in lm_studio_service.chat_completion_stream(chat_request):
                if chunk.strip():
                    yield f"data: {json.dumps({'type': 'content', 'content': chunk})}\n\n"
            
            # å‘é€å®Œæˆä¿¡å·
            yield f"data: {json.dumps({'type': 'complete'})}\n\n"
            yield "data: [DONE]\n\n"
            
        except Exception as e:
            logger.error(f"æµå¼å¤šæ¨¡æ€èŠå¤©å¤±è´¥: {e}")
            error_message = f"å¤„ç†è¯·æ±‚æ—¶å‡ºç°é”™è¯¯: {str(e)}"
            yield f"data: {json.dumps({'type': 'error', 'message': error_message})}\n\n"
            yield "data: [DONE]\n\n"
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )

@router.post("/rag/process")
async def process_document_for_rag(
    content: str = Form(...),
    filename: str = Form(...),
    file_type: str = Form(...)
):
    """å¤„ç†æ–‡æ¡£è¿›è¡ŒRAGç´¢å¼•"""
    try:
        start_time = time.time()
        
        # å¤„ç†æ–‡æ¡£å¹¶ç”Ÿæˆdoc_id
        doc_id = await rag_service.process_document(
            content=content,
            filename=filename,
            file_type=file_type
        )
        
        processing_time = time.time() - start_time
        
        return {
            "doc_id": doc_id,
            "message": "æ–‡æ¡£å¤„ç†å®Œæˆ",
            "processing_time": processing_time
        }
        
    except Exception as e:
        logger.error(f"RAGæ–‡æ¡£å¤„ç†å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ–‡æ¡£å¤„ç†å¤±è´¥: {str(e)}")

@router.get("/rag/documents")
async def get_all_documents():
    """è·å–æ‰€æœ‰RAGæ–‡æ¡£åˆ—è¡¨"""
    try:
        start_time = time.time()
        
        # è·å–æ–‡æ¡£åˆ—è¡¨
        documents = await rag_service.get_all_documents()
        
        processing_time = time.time() - start_time
        
        return {
            "documents": documents,
            "total_count": len(documents),
            "processing_time": processing_time
        }
        
    except Exception as e:
        logger.error(f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {str(e)}")

@router.post("/rag/search", response_model=RAGSearchResponse)
async def search_documents(request: RAGSearchRequest):
    """RAGæ–‡æ¡£æ£€ç´¢æ¥å£"""
    try:
        start_time = time.time()
        
        # æ‰§è¡Œæ£€ç´¢
        chunks = await rag_service.search_relevant_chunks(
            query=request.query,
            doc_ids=request.doc_ids,
            top_k=request.top_k,
            min_similarity=request.min_similarity
        )
        
        search_time = time.time() - start_time
        
        return RAGSearchResponse(
            chunks=chunks,
            total_found=len(chunks),
            search_time=search_time
        )
        
    except Exception as e:
        logger.error(f"RAGæ£€ç´¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ£€ç´¢å¤±è´¥: {str(e)}")

@router.get("/rag/documents/{doc_id}", response_model=DocumentInfo)
async def get_document_info(doc_id: str):
    """è·å–æ–‡æ¡£ä¿¡æ¯"""
    try:
        doc_info = await rag_service.get_document_info(doc_id)
        
        if not doc_info:
            raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")
        
        return DocumentInfo(**doc_info)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æ–‡æ¡£ä¿¡æ¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡æ¡£ä¿¡æ¯å¤±è´¥: {str(e)}")

@router.delete("/rag/documents/{doc_id}")
async def delete_document(doc_id: str):
    """åˆ é™¤æ–‡æ¡£åŠå…¶ç´¢å¼•"""
    try:
        success = await rag_service.delete_document(doc_id)
        
        if not success:
            raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")
        
        return {"message": "æ–‡æ¡£åˆ é™¤æˆåŠŸ", "doc_id": doc_id}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤æ–‡æ¡£å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤æ–‡æ¡£å¤±è´¥: {str(e)}")