"""
ç”¨æˆ·ç»‘å®šçš„RAGæœåŠ¡
ä¸ºæ¯ä¸ªç”¨æˆ·åˆ›å»ºç‹¬ç«‹çš„ChromaDBé›†åˆï¼Œå®ç°æ•°æ®éš”ç¦»
"""

import os
import logging
from typing import List, Dict, Any, Optional, Tuple
import uuid
from datetime import datetime

import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
import PyPDF2
from docx import Document
import aiofiles

from app.database import Database
from app.config import settings

logger = logging.getLogger(__name__)

class UserRAGService:
    """ç”¨æˆ·ç»‘å®šçš„RAGæœåŠ¡"""
    
    def __init__(self):
        self.db = Database()
        self.chroma_client = None
        self.embedding_model = None
        self._initialized = False
    
    async def initialize(self):
        """åˆå§‹åŒ–RAGæœåŠ¡"""
        if self._initialized:
            return
        
        try:
            # åˆå§‹åŒ–ChromaDBå®¢æˆ·ç«¯
            chroma_dir = os.path.join(settings.upload_dir, "chromadb")
            os.makedirs(chroma_dir, exist_ok=True)
            
            self.chroma_client = chromadb.PersistentClient(
                path=chroma_dir,
                settings=Settings(
                    allow_reset=True,
                    anonymized_telemetry=False
                )
            )
            
            # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
            logger.info("ğŸ”— åŠ è½½åµŒå…¥æ¨¡å‹...")
            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
            
            self._initialized = True
            logger.info("âœ… ç”¨æˆ·RAGæœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ ç”¨æˆ·RAGæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            raise e
    
    def _get_user_collection_name(self, user_id: int) -> str:
        """è·å–ç”¨æˆ·ä¸“å±çš„é›†åˆåç§°"""
        return f"user_{user_id}_docs"
    
    async def get_user_collection(self, user_id: int):
        """è·å–æˆ–åˆ›å»ºç”¨æˆ·ä¸“å±çš„ChromaDBé›†åˆ"""
        if not self._initialized:
            await self.initialize()
        
        collection_name = self._get_user_collection_name(user_id)
        
        try:
            # å°è¯•è·å–ç°æœ‰é›†åˆ
            collection = self.chroma_client.get_collection(collection_name)
        except ValueError:
            # é›†åˆä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°é›†åˆ
            collection = self.chroma_client.create_collection(
                name=collection_name,
                metadata={"hnsw:space": "cosine"}
            )
            logger.info(f"ä¸ºç”¨æˆ· {user_id} åˆ›å»ºæ–°çš„æ–‡æ¡£é›†åˆ: {collection_name}")
        
        return collection
    
    async def add_document(self, user_id: int, file_path: str, title: str = None) -> str:
        """ä¸ºç”¨æˆ·æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
        try:
            # ç”Ÿæˆæ–‡æ¡£ID
            doc_id = str(uuid.uuid4())
            
            # æå–æ–‡æ¡£å†…å®¹
            content = await self._extract_text_from_file(file_path)
            if not content.strip():
                raise ValueError("æ— æ³•ä»æ–‡æ¡£ä¸­æå–æœ‰æ•ˆå†…å®¹")
            
            # åˆ†å—å¤„ç†æ–‡æ¡£
            chunks = self._split_text(content)
            
            # è·å–ç”¨æˆ·é›†åˆ
            collection = await self.get_user_collection(user_id)
            
            # ç”ŸæˆåµŒå…¥
            embeddings = self.embedding_model.encode(chunks).tolist()
            
            # å‡†å¤‡å…ƒæ•°æ®
            metadatas = []
            ids = []
            for i, chunk in enumerate(chunks):
                chunk_id = f"{doc_id}_chunk_{i}"
                ids.append(chunk_id)
                metadatas.append({
                    "doc_id": doc_id,
                    "chunk_index": i,
                    "file_path": file_path,
                    "title": title or os.path.basename(file_path),
                    "created_at": datetime.now().isoformat()
                })
            
            # æ·»åŠ åˆ°ChromaDB
            collection.add(
                embeddings=embeddings,
                documents=chunks,
                metadatas=metadatas,
                ids=ids
            )
            
            # ä¿å­˜æ–‡æ¡£ä¿¡æ¯åˆ°æ•°æ®åº“
            await self._save_document_to_db(user_id, doc_id, file_path, title, len(chunks))
            
            logger.info(f"ç”¨æˆ· {user_id} æ·»åŠ æ–‡æ¡£æˆåŠŸ: {title}, åˆ†å—æ•°: {len(chunks)}")
            return doc_id
            
        except Exception as e:
            logger.error(f"æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            raise e
    
    async def search_documents(self, user_id: int, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """åœ¨ç”¨æˆ·çš„çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³æ–‡æ¡£"""
        try:
            collection = await self.get_user_collection(user_id)
            
            # ç”ŸæˆæŸ¥è¯¢åµŒå…¥
            query_embedding = self.embedding_model.encode([query]).tolist()[0]
            
            # åœ¨ChromaDBä¸­æœç´¢
            results = collection.query(
                query_embeddings=[query_embedding],
                n_results=top_k
            )
            
            # æ ¼å¼åŒ–ç»“æœ
            search_results = []
            if results['documents'] and results['documents'][0]:
                for i in range(len(results['documents'][0])):
                    search_results.append({
                        "id": results['ids'][0][i],
                        "content": results['documents'][0][i],
                        "metadata": results['metadatas'][0][i],
                        "similarity": 1 - results['distances'][0][i]  # è½¬æ¢è·ç¦»ä¸ºç›¸ä¼¼åº¦
                    })
            
            return search_results
            
        except Exception as e:
            logger.error(f"æœç´¢æ–‡æ¡£å¤±è´¥: {e}")
            return []
    
    async def get_user_documents(self, user_id: int) -> List[Dict[str, Any]]:
        """è·å–ç”¨æˆ·çš„æ–‡æ¡£åˆ—è¡¨"""
        try:
            query = """
                SELECT doc_id, title, file_path, chunk_count, created_at, updated_at
                FROM user_documents 
                WHERE user_id = ? 
                ORDER BY created_at DESC
            """
            
            async with self.db.get_connection() as conn:
                cursor = await conn.execute(query, (user_id,))
                rows = await cursor.fetchall()
                
                documents = []
                for row in rows:
                    documents.append({
                        "doc_id": row[0],
                        "title": row[1],
                        "file_path": row[2],
                        "chunk_count": row[3],
                        "created_at": row[4],
                        "updated_at": row[5]
                    })
                
                return documents
                
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    async def delete_document(self, user_id: int, doc_id: str) -> bool:
        """åˆ é™¤ç”¨æˆ·çš„æ–‡æ¡£"""
        try:
            collection = await self.get_user_collection(user_id)
            
            # è·å–æ–‡æ¡£çš„æ‰€æœ‰åˆ†å—ID
            chunk_ids = []
            result = collection.get(where={"doc_id": doc_id})
            if result['ids']:
                chunk_ids = result['ids']
            
            # ä»ChromaDBåˆ é™¤
            if chunk_ids:
                collection.delete(ids=chunk_ids)
            
            # ä»æ•°æ®åº“åˆ é™¤è®°å½•
            await self._delete_document_from_db(user_id, doc_id)
            
            logger.info(f"ç”¨æˆ· {user_id} åˆ é™¤æ–‡æ¡£æˆåŠŸ: {doc_id}")
            return True
            
        except Exception as e:
            logger.error(f"åˆ é™¤æ–‡æ¡£å¤±è´¥: {e}")
            return False
    
    async def _extract_text_from_file(self, file_path: str) -> str:
        """ä»æ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹"""
        _, ext = os.path.splitext(file_path.lower())
        
        try:
            if ext == '.pdf':
                return await self._extract_from_pdf(file_path)
            elif ext in ['.docx', '.doc']:
                return await self._extract_from_docx(file_path)
            elif ext == '.txt':
                return await self._extract_from_txt(file_path)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {ext}")
        except Exception as e:
            logger.error(f"æå–æ–‡ä»¶å†…å®¹å¤±è´¥: {e}")
            raise e
    
    async def _extract_from_pdf(self, file_path: str) -> str:
        """ä»PDFæ–‡ä»¶æå–æ–‡æœ¬"""
        text = ""
        try:
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\n"
        except Exception as e:
            logger.error(f"PDFæ–‡æœ¬æå–å¤±è´¥: {e}")
            raise e
        
        return text.strip()
    
    async def _extract_from_docx(self, file_path: str) -> str:
        """ä»DOCXæ–‡ä»¶æå–æ–‡æœ¬"""
        try:
            doc = Document(file_path)
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            return text.strip()
        except Exception as e:
            logger.error(f"DOCXæ–‡æœ¬æå–å¤±è´¥: {e}")
            raise e
    
    async def _extract_from_txt(self, file_path: str) -> str:
        """ä»TXTæ–‡ä»¶æå–æ–‡æœ¬"""
        try:
            async with aiofiles.open(file_path, 'r', encoding='utf-8') as file:
                content = await file.read()
            return content.strip()
        except Exception as e:
            logger.error(f"TXTæ–‡æœ¬æå–å¤±è´¥: {e}")
            raise e
    
    def _split_text(self, text: str, chunk_size: int = 1000, overlap: int = 200) -> List[str]:
        """å°†æ–‡æœ¬åˆ†å‰²æˆè¾ƒå°çš„å—"""
        if len(text) <= chunk_size:
            return [text]
        
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + chunk_size
            
            # å¦‚æœä¸æ˜¯æœ€åä¸€å—ï¼Œå°è¯•åœ¨å¥å·å¤„åˆ†å‰²
            if end < len(text):
                # å¯»æ‰¾æœ€è¿‘çš„å¥å·
                last_period = text.rfind('.', start, end)
                if last_period > start:
                    end = last_period + 1
            
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)
            
            # è®¾ç½®ä¸‹ä¸€å—çš„å¼€å§‹ä½ç½®ï¼Œè€ƒè™‘é‡å 
            start = max(start + 1, end - overlap)
            
            if start >= len(text):
                break
        
        return chunks
    
    async def _save_document_to_db(self, user_id: int, doc_id: str, file_path: str, title: str, chunk_count: int):
        """ä¿å­˜æ–‡æ¡£ä¿¡æ¯åˆ°æ•°æ®åº“"""
        query = """
            INSERT INTO user_documents (user_id, doc_id, title, file_path, chunk_count, created_at, updated_at)
            VALUES (?, ?, ?, ?, ?, datetime('now'), datetime('now'))
        """
        
        async with self.db.get_connection() as conn:
            await conn.execute(query, (user_id, doc_id, title, file_path, chunk_count))
            await conn.commit()
    
    async def _delete_document_from_db(self, user_id: int, doc_id: str):
        """ä»æ•°æ®åº“åˆ é™¤æ–‡æ¡£è®°å½•"""
        query = "DELETE FROM user_documents WHERE user_id = ? AND doc_id = ?"
        
        async with self.db.get_connection() as conn:
            await conn.execute(query, (user_id, doc_id))
            await conn.commit()

# åˆ›å»ºå…¨å±€å®ä¾‹
user_rag_service = UserRAGService() 