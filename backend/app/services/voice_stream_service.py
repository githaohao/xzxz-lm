"""
æµå¼è¯­éŸ³èŠå¤©æœåŠ¡

æä¾›æµå¼è¯­éŸ³è¯†åˆ«ã€AIå¯¹è¯å’ŒTTSåˆæˆåŠŸèƒ½
"""

import json
import base64
import logging
from typing import AsyncGenerator
from app.services.funaudio_service_real import FunAudioLLMService
from app.services.lm_studio_service import lm_studio_service
from app.models.schemas import ChatRequest
from app.utils import clean_text_for_speech, synthesize_speech_chunk

logger = logging.getLogger(__name__)

class VoiceStreamService:
    """æµå¼è¯­éŸ³èŠå¤©æœåŠ¡"""
    
    def __init__(self):
        self.funaudio_service = FunAudioLLMService()
    
    async def generate_streaming_response(
        self, 
        audio_data: bytes, 
        session_id: str, 
        language: str = "auto",
        knowledge_base_id: str = None
    ) -> AsyncGenerator[str, None]:
        """ç”Ÿæˆæµå¼è¯­éŸ³èŠå¤©å“åº”"""
        try:
            # ç¬¬ä¸€æ­¥ï¼šè¯­éŸ³è¯†åˆ«
            yield f"data: {json.dumps({'type': 'status', 'message': 'æ­£åœ¨è¯†åˆ«è¯­éŸ³...'})}\n\n"
            
            # ä½¿ç”¨FunAudioLLMè¿›è¡Œè¯­éŸ³è¯†åˆ«
            recognition_result = await self.funaudio_service.voice_recognition(audio_data, language)
            
            if not recognition_result["success"]:
                yield f"data: {json.dumps({'type': 'error', 'message': 'è¯­éŸ³è¯†åˆ«å¤±è´¥'})}\n\n"
                return
            
            recognized_text = recognition_result["recognized_text"]
            
            if not recognized_text.strip():
                yield f"data: {json.dumps({'type': 'error', 'message': 'æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³å†…å®¹'})}\n\n"
                return
            
            # å‘é€è¯†åˆ«ç»“æœ
            yield f"data: {json.dumps({'type': 'recognition', 'text': recognized_text})}\n\n"
            
            # ç¬¬äºŒæ­¥ï¼šå‡†å¤‡AIèŠå¤©è¯·æ±‚
            yield f"data: {json.dumps({'type': 'status', 'message': 'AIæ­£åœ¨æ€è€ƒ...'})}\n\n"
            
            chat_request = ChatRequest(
                message=recognized_text,
                history=[],  # å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ å†å²è®°å½•
                temperature=0.7,
                max_tokens=2048,
                stream=True
            )
            
            # ç¬¬ä¸‰æ­¥ï¼šæµå¼AIå¯¹è¯ + å®æ—¶TTS
            await self._process_streaming_ai_response(chat_request)
            
        except Exception as e:
            logger.error(f"æµå¼è¯­éŸ³èŠå¤©å¤„ç†å¤±è´¥: {e}")
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
    
    async def _process_streaming_ai_response(self, chat_request: ChatRequest) -> AsyncGenerator[str, None]:
        """å¤„ç†æµå¼AIå“åº”å’ŒTTSåˆæˆ"""
        text_buffer = ""
        processed_text_length = 0  # è®°å½•å·²å¤„ç†çš„æ–‡æœ¬é•¿åº¦
        chunk_counter = 0
        
        async for ai_chunk in lm_studio_service.chat_completion_stream(chat_request):
            if ai_chunk.strip():
                text_buffer += ai_chunk
                
                # å‘é€AIç”Ÿæˆçš„æ–‡å­—ç‰‡æ®µ
                yield f"data: {json.dumps({'type': 'ai_text', 'content': ai_chunk})}\n\n"
                
                # æ¸…ç†æ€è€ƒæ ‡ç­¾
                cleaned_buffer = clean_text_for_speech(text_buffer)
                
                # åªå¤„ç†æ–°å¢çš„éƒ¨åˆ†ï¼Œé¿å…é‡å¤å¤„ç†
                if len(cleaned_buffer) > processed_text_length:
                    # è·å–æ–°å¢çš„æ–‡æœ¬éƒ¨åˆ†
                    new_text = cleaned_buffer[processed_text_length:]
                    
                    # æ£€æŸ¥æ–°æ–‡æœ¬æ˜¯å¦å¯ä»¥å½¢æˆå®Œæ•´çš„å¥å­è¿›è¡ŒTTS
                    # å¯»æ‰¾å¥å­ç»“æŸæ ‡è®°
                    sentence_endings = ['ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?', '\n']
                    last_sentence_end = -1
                    
                    for i, char in enumerate(new_text):
                        if char in sentence_endings:
                            last_sentence_end = i
                    
                    # å¦‚æœæ‰¾åˆ°å®Œæ•´å¥å­ï¼Œè¿›è¡ŒTTSåˆæˆ
                    if last_sentence_end >= 0:
                        # æå–å®Œæ•´çš„å¥å­ï¼ˆåŒ…æ‹¬ä¹‹å‰æœªå¤„ç†çš„éƒ¨åˆ†ï¼‰
                        sentence_to_process = new_text[:last_sentence_end + 1].strip()
                        
                        if sentence_to_process and len(sentence_to_process) >= 3:
                            try:
                                logger.info(f"ğŸµ å¤„ç†å®Œæ•´å¥å­: {repr(sentence_to_process[:100])}")
                                
                                # TTSåˆæˆ
                                audio_buffer = await synthesize_speech_chunk(sentence_to_process)
                                if audio_buffer:
                                    # å°†éŸ³é¢‘æ•°æ®ç¼–ç ä¸ºbase64
                                    audio_base64 = base64.b64encode(audio_buffer).decode('utf-8')
                                    
                                    # å‘é€éŸ³é¢‘æ•°æ®
                                    yield f"data: {json.dumps({'type': 'audio_chunk', 'audio': audio_base64, 'text': sentence_to_process, 'chunk_id': chunk_counter})}\n\n"
                                    chunk_counter += 1
                                    
                                    logger.info(f"âœ… éŸ³é¢‘å— {chunk_counter-1} å‘é€æˆåŠŸ: {len(audio_buffer)} å­—èŠ‚")
                                else:
                                    logger.info(f"âš ï¸ å¥å­TTSè·³è¿‡: {repr(sentence_to_process[:50])}")
                                    
                            except Exception as e:
                                logger.error(f"âŒ å¥å­TTSåˆæˆå¼‚å¸¸: {e}, æ–‡æœ¬: {repr(sentence_to_process[:100])}")
                                yield f"data: {json.dumps({'type': 'tts_error', 'message': f'è¯­éŸ³åˆæˆå¤±è´¥: {str(e)}', 'text': sentence_to_process[:100]})}\n\n"
                        
                        # æ›´æ–°å·²å¤„ç†çš„æ–‡æœ¬é•¿åº¦
                        processed_text_length += last_sentence_end + 1
                    
                    # å¦‚æœç¼“å†²åŒºå¤ªé•¿ä½†æ²¡æœ‰å¥å­ç»“æŸç¬¦ï¼Œå¼ºåˆ¶å¤„ç†ä¸€éƒ¨åˆ†
                    elif len(new_text) > 100:
                        # å¯»æ‰¾åˆé€‚çš„åˆ†å‰²ç‚¹ï¼ˆç©ºæ ¼ã€é€—å·ç­‰ï¼‰
                        split_chars = [' ', 'ï¼Œ', ',', 'ã€', 'ï¼›', ';']
                        best_split = -1
                        
                        # åœ¨å‰80ä¸ªå­—ç¬¦ä¸­å¯»æ‰¾åˆ†å‰²ç‚¹
                        for i in range(min(80, len(new_text) - 1), 20, -1):
                            if new_text[i] in split_chars:
                                best_split = i
                                break
                        
                        if best_split > 20:
                            chunk_to_process = new_text[:best_split + 1].strip()
                            
                            if chunk_to_process:
                                try:
                                    logger.info(f"ğŸµ å¤„ç†é•¿æ–‡æœ¬å—: {repr(chunk_to_process[:100])}")
                                    
                                    # TTSåˆæˆ
                                    audio_buffer = await synthesize_speech_chunk(chunk_to_process)
                                    if audio_buffer:
                                        audio_base64 = base64.b64encode(audio_buffer).decode('utf-8')
                                        yield f"data: {json.dumps({'type': 'audio_chunk', 'audio': audio_base64, 'text': chunk_to_process, 'chunk_id': chunk_counter})}\n\n"
                                        chunk_counter += 1
                                        logger.info(f"âœ… é•¿æ–‡æœ¬éŸ³é¢‘å— {chunk_counter-1} å‘é€æˆåŠŸ: {len(audio_buffer)} å­—èŠ‚")
                                    
                                except Exception as e:
                                    logger.error(f"âŒ é•¿æ–‡æœ¬TTSåˆæˆå¼‚å¸¸: {e}")
                            
                            # æ›´æ–°å·²å¤„ç†çš„æ–‡æœ¬é•¿åº¦
                            processed_text_length += best_split + 1
        
        # å¤„ç†å‰©ä½™çš„æ–‡æœ¬ç¼“å†²åŒº
        if text_buffer.strip():
            try:
                # æ¸…ç†å‰©ä½™æ–‡æœ¬
                cleaned_buffer = clean_text_for_speech(text_buffer)
                
                # è·å–æœªå¤„ç†çš„å‰©ä½™æ–‡æœ¬
                if len(cleaned_buffer) > processed_text_length:
                    remaining_text = cleaned_buffer[processed_text_length:].strip()
                    
                    if remaining_text and len(remaining_text) >= 3:
                        logger.info(f"ğŸ”š å¤„ç†å‰©ä½™æ–‡æœ¬: {repr(remaining_text[:100])}")
                        audio_buffer = await synthesize_speech_chunk(remaining_text)
                        if audio_buffer:
                            audio_base64 = base64.b64encode(audio_buffer).decode('utf-8')
                            yield f"data: {json.dumps({'type': 'audio_chunk', 'audio': audio_base64, 'text': remaining_text, 'chunk_id': chunk_counter})}\n\n"
                            logger.info(f"âœ… æœ€ç»ˆéŸ³é¢‘å—å‘é€æˆåŠŸ: {len(audio_buffer)} å­—èŠ‚")
                        else:
                            logger.info(f"âš ï¸ æœ€ç»ˆæ–‡æœ¬å—TTSè·³è¿‡: {repr(remaining_text[:50])}")
                    else:
                        logger.info("å‰©ä½™æ–‡æœ¬å¤ªçŸ­æˆ–ä¸ºç©ºï¼Œè·³è¿‡TTSåˆæˆ")
                else:
                    logger.info("æ‰€æœ‰æ–‡æœ¬å·²å¤„ç†å®Œæ¯•ï¼Œæ— å‰©ä½™æ–‡æœ¬")
            except Exception as e:
                logger.error(f"âŒ æœ€ç»ˆTTSåˆæˆå¤±è´¥: {e}, åŸå§‹æ–‡æœ¬: {repr(text_buffer[:200])}")
                yield f"data: {json.dumps({'type': 'tts_error', 'message': f'æœ€ç»ˆè¯­éŸ³åˆæˆå¤±è´¥: {str(e)}', 'text': text_buffer[:100]})}\n\n"
        
        # å‘é€å®Œæˆä¿¡å·
        yield f"data: {json.dumps({'type': 'complete'})}\n\n"
        yield "data: [DONE]\n\n"
    
    async def process_speech_synthesis(self, text: str, voice: str = "zh-CN-XiaoxiaoNeural", rate: float = 1.0) -> bytes:
        """å¤„ç†è¯­éŸ³åˆæˆè¯·æ±‚"""
        try:
            # æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤æ€è€ƒæ ‡ç­¾å’Œè¡¨æƒ…ç¬¦å·
            clean_text = clean_text_for_speech(text)
            
            if not clean_text.strip():
                logger.warning("æ¸…ç†åçš„æ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡è¯­éŸ³åˆæˆ")
                return b""
            
            # è°ƒç”¨TTSåˆæˆ
            audio_buffer = await synthesize_speech_chunk(clean_text)
            return audio_buffer or b""
            
        except Exception as e:
            logger.error(f"âŒ è¯­éŸ³åˆæˆå¤±è´¥: {e}")
            raise e

# åˆ›å»ºå…¨å±€æœåŠ¡å®ä¾‹
voice_stream_service = VoiceStreamService() 