import logging
import torch
import numpy as np
from typing import Optional, Dict, Any, List
from io import BytesIO
import asyncio
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess

# å¯¼å…¥å·¥å…·æ¨¡å—
from app.utils import (
    DeviceManager, AudioProcessor, EmotionAnalyzer, 
    MessageProcessor, get_timestamp
)

logger = logging.getLogger(__name__)

class FunAudioLLMService:
    """
    åŸºäºé˜¿é‡ŒFunAudioLLMçš„è¯­éŸ³æœåŠ¡
    é›†æˆSenseVoiceè¿›è¡Œé«˜æ€§èƒ½è¯­éŸ³è¯†åˆ«ã€æƒ…æ„Ÿåˆ†æå’Œå£°å­¦äº‹ä»¶æ£€æµ‹
    å®˜æ–¹ä»“åº“ï¼šhttps://github.com/FunAudioLLM
    """
    
    def __init__(self):
        self.model = None
        self.device = DeviceManager.get_optimal_device()
        
        # å¯¹è¯å†å²ç®¡ç†
        self.conversation_history: Dict[str, List[Dict[str, Any]]] = {}
        self.max_history_length = 20
        
        logger.info(f"ğŸ¤ åˆå§‹åŒ–FunAudioLLMæœåŠ¡ï¼Œè®¾å¤‡: {self.device}")
        
        # è®¾å¤‡ä¼˜åŒ–é…ç½®
        optimization_result = DeviceManager.setup_device_optimization(self.device)
        if optimization_result["success"]:
            logger.info(f"âœ… è®¾å¤‡ä¼˜åŒ–å·²å¯ç”¨: {optimization_result['optimizations']}")
        else:
            logger.warning(f"âš ï¸ è®¾å¤‡ä¼˜åŒ–é…ç½®å¤±è´¥: {optimization_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
    async def initialize(self):
        """åˆå§‹åŒ–SenseVoiceæ¨¡å‹"""
        try:
            logger.info("ğŸ“¥ åŠ è½½SenseVoiceæ¨¡å‹...")
            
            # åŠ è½½SenseVoiceæ¨¡å‹
            self.model = AutoModel(
                model="iic/SenseVoiceSmall",
                trust_remote_code=True,
                vad_model="fsmn-vad",
                vad_kwargs={"max_single_segment_time": 30000},
                device=self.device,
            )
            
            logger.info("âœ… FunAudioLLM SenseVoiceæ¨¡å‹åŠ è½½æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ FunAudioLLMæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def _save_audio_temp(self, audio_data: bytes) -> str:
        """ä¿å­˜éŸ³é¢‘æ•°æ®åˆ°ä¸´æ—¶æ–‡ä»¶"""
        return AudioProcessor.save_audio_temp(audio_data)
    
    async def voice_recognition(self, audio_data: bytes, language: str = "auto") -> Dict[str, Any]:
        """
        é«˜æ€§èƒ½è¯­éŸ³è¯†åˆ«ï¼Œæ”¯æŒæƒ…æ„Ÿåˆ†æå’Œå£°å­¦äº‹ä»¶æ£€æµ‹
        """
        try:
            if not self.model:
                await self.initialize()
            
            logger.info("ğŸ¯ å¼€å§‹FunAudioLLMè¯­éŸ³è¯†åˆ«...")
            
            # ä¿å­˜éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
            temp_audio_path = self._save_audio_temp(audio_data)
            
            try:
                # ä½¿ç”¨SenseVoiceè¿›è¡Œè¯†åˆ«
                result = self.model.generate(
                    input=temp_audio_path,
                    cache={},
                    language=language,  # "auto", "zh", "en", "yue", "ja", "ko", "nospeech"
                    use_itn=True,
                    batch_size_s=60,
                    merge_vad=True,
                    merge_length_s=15,
                )
                
                # å¤„ç†è¯†åˆ«ç»“æœï¼Œæå–æ–‡æœ¬å’Œæƒ…æ„Ÿä¿¡æ¯
                raw_text = result[0]["text"]
                processed_text = rich_transcription_postprocess(raw_text)
                
                # è§£ææƒ…æ„Ÿå’Œäº‹ä»¶ä¿¡æ¯
                emotion_info = self._extract_emotion_info(processed_text)
                event_info = self._extract_event_info(processed_text)
                clean_text = self._clean_text(processed_text)
                
                logger.info(f"âœ… è¯­éŸ³è¯†åˆ«æˆåŠŸ: {clean_text[:50]}...")
                
                return {
                    "success": True,
                    "recognized_text": clean_text,
                    "raw_text": raw_text,
                    "processed_text": processed_text,
                    "emotion": emotion_info,
                    "events": event_info,
                    "language": language,
                    "engine": "FunAudioLLM-SenseVoice",
                    "confidence": result[0].get("confidence", 1.0)
                }
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                AudioProcessor.cleanup_temp_file(temp_audio_path)
            
        except Exception as e:
            logger.error(f"âŒ FunAudioLLMè¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "engine": "FunAudioLLM-SenseVoice",
                "recognized_text": ""
            }
    
    async def voice_chat(self, audio_data: bytes, session_id: str = "default", language: str = "auto") -> Dict[str, Any]:
        """
        è¯­éŸ³èŠå¤©æ¨¡å¼ - ç»“åˆè¯­éŸ³è¯†åˆ«å’Œå¯¹è¯ç”Ÿæˆ
        """
        try:
            logger.info(f"ğŸ—£ï¸ å¼€å§‹FunAudioLLMè¯­éŸ³èŠå¤©ï¼Œä¼šè¯ID: {session_id}")
            
            # é¦–å…ˆè¿›è¡Œè¯­éŸ³è¯†åˆ«
            recognition_result = await self.voice_recognition(audio_data, language)
            
            if not recognition_result["success"]:
                return recognition_result
            
            recognized_text = recognition_result["recognized_text"]
            emotion_info = recognition_result["emotion"]
            
            # è·å–æˆ–åˆå§‹åŒ–å¯¹è¯å†å²
            if session_id not in self.conversation_history:
                self.conversation_history[session_id] = []
            
            # æ„å»ºåŒ…å«æƒ…æ„Ÿä¿¡æ¯çš„ç”¨æˆ·æ¶ˆæ¯
            user_message = MessageProcessor.format_user_message(
                recognized_text, emotion_info, get_timestamp()
            )
            
            # æ·»åŠ åˆ°å†å²
            self.conversation_history[session_id].append(user_message)
            
            # è¿™é‡Œå¯ä»¥é›†æˆå…¶ä»–LLMè¿›è¡Œå¯¹è¯ç”Ÿæˆ
            # æš‚æ—¶è¿”å›è¯†åˆ«ç»“æœå’Œç®€å•å›å¤
            response_text = self._generate_response(recognized_text, emotion_info)
            
            # æ·»åŠ AIå›å¤åˆ°å†å²
            ai_message = MessageProcessor.format_assistant_message(
                response_text, get_timestamp()
            )
            self.conversation_history[session_id].append(ai_message)
            
            # é™åˆ¶å†å²é•¿åº¦
            self.conversation_history[session_id] = MessageProcessor.limit_conversation_history(
                self.conversation_history[session_id], self.max_history_length
            )
            
            logger.info(f"âœ… FunAudioLLMè¯­éŸ³èŠå¤©æˆåŠŸ")
            
            return {
                "success": True,
                "recognized_text": recognized_text,
                "response": response_text,
                "emotion": emotion_info,
                "events": recognition_result["events"],
                "session_id": session_id,
                "history_length": len(self.conversation_history[session_id]) // 2,
                "engine": "FunAudioLLM-SenseVoice",
                "language": language
            }
            
        except Exception as e:
            logger.error(f"âŒ FunAudioLLMè¯­éŸ³èŠå¤©å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "engine": "FunAudioLLM-SenseVoice",
                "response": "æŠ±æ­‰ï¼Œè¯­éŸ³å¤„ç†å‡ºç°é—®é¢˜ã€‚è¯·ç¨åé‡è¯•ã€‚"
            }
    
    def _extract_emotion_info(self, text: str) -> Dict[str, Any]:
        """æå–æƒ…æ„Ÿä¿¡æ¯"""
        return EmotionAnalyzer.extract_emotion_info(text)
    
    def _extract_event_info(self, text: str) -> List[str]:
        """æå–å£°å­¦äº‹ä»¶ä¿¡æ¯"""
        return EmotionAnalyzer.extract_event_info(text)
    
    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤æƒ…æ„Ÿå’Œäº‹ä»¶æ ‡è®°"""
        return EmotionAnalyzer.clean_text(text)
    
    def _generate_response(self, user_text: str, emotion_info: Dict[str, Any]) -> str:
        """ç”Ÿæˆç®€å•çš„å›å¤ï¼ˆå¯æ‰©å±•æ¥å…¥å…¶ä»–LLMï¼‰"""
        primary_emotion = emotion_info.get("primary", "neutral")
        
        if primary_emotion == "happy":
            return f"å¾ˆé«˜å…´å¬åˆ°ä½ å¼€å¿ƒçš„è¯è¯­ï¼ä½ è¯´ï¼šã€Œ{user_text}ã€"
        elif primary_emotion == "sad":
            return f"æˆ‘èƒ½æ„Ÿå—åˆ°ä½ çš„æƒ…ç»ªï¼Œè®©æˆ‘æ¥å¸®åŠ©ä½ ã€‚ä½ è¯´ï¼šã€Œ{user_text}ã€"
        elif primary_emotion == "angry":
            return f"æˆ‘ç†è§£ä½ çš„æ„Ÿå—ï¼Œè®©æˆ‘ä»¬å†·é™åœ°è®¨è®ºä¸€ä¸‹ã€‚ä½ è¯´ï¼šã€Œ{user_text}ã€" 
        else:
            return f"æˆ‘å¬åˆ°ä½ è¯´ï¼šã€Œ{user_text}ã€ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"
    

    
    async def clear_conversation_history(self, session_id: str = "default") -> bool:
        """æ¸…é™¤æŒ‡å®šä¼šè¯çš„å¯¹è¯å†å²"""
        try:
            if session_id in self.conversation_history:
                del self.conversation_history[session_id]
                logger.info(f"âœ… å·²æ¸…é™¤FunAudioLLMä¼šè¯ {session_id} çš„å¯¹è¯å†å²")
            return True
        except Exception as e:
            logger.error(f"âŒ æ¸…é™¤å¯¹è¯å†å²å¤±è´¥: {e}")
            return False
    
    async def get_conversation_summary(self, session_id: str = "default") -> Dict[str, Any]:
        """è·å–å¯¹è¯æ‘˜è¦ä¿¡æ¯"""
        try:
            history = self.conversation_history.get(session_id, [])
            user_messages = [msg for msg in history if msg["role"] == "user"]
            assistant_messages = [msg for msg in history if msg["role"] == "assistant"]
            
            # ç»Ÿè®¡æƒ…æ„Ÿåˆ†å¸ƒ
            emotions = [msg.get("emotion", {}).get("primary", "neutral") for msg in user_messages if "emotion" in msg]
            emotion_stats = {emotion: emotions.count(emotion) for emotion in set(emotions)} if emotions else {}
            
            return {
                "session_id": session_id,
                "total_messages": len(history),
                "user_messages": len(user_messages),
                "assistant_messages": len(assistant_messages),
                "conversation_rounds": len(user_messages),
                "emotion_stats": emotion_stats,
                "has_history": len(history) > 0,
                "last_user_message": user_messages[-1]["content"] if user_messages else None,
                "last_assistant_message": assistant_messages[-1]["content"] if assistant_messages else None,
                "engine": "FunAudioLLM-SenseVoice"
            }
        except Exception as e:
            logger.error(f"âŒ è·å–å¯¹è¯æ‘˜è¦å¤±è´¥: {e}")
            return {"error": str(e)}
    
    async def health_check(self) -> Dict[str, Any]:
        """æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€"""
        try:
            if not self.model:
                await self.initialize()
            
            return {
                "available": self.model is not None,
                "model_name": "FunAudioLLM-SenseVoice",
                "device": self.device,
                "cuda_available": torch.cuda.is_available(),
                "features": [
                    "é«˜æ€§èƒ½è¯­éŸ³è¯†åˆ« (æ¯”Whisperå¿«15å€)",
                    "æƒ…æ„Ÿè¯†åˆ«",
                    "å£°å­¦äº‹ä»¶æ£€æµ‹", 
                    "50+è¯­è¨€æ”¯æŒ",
                    "è¿ç»­å¯¹è¯",
                    "å¤šä¼šè¯ç®¡ç†"
                ],
                "message": "FunAudioLLMæœåŠ¡æ­£å¸¸" if self.model else "æ¨¡å‹æœªåŠ è½½",
                "supported_languages": ["auto", "zh", "en", "yue", "ja", "ko", "fr", "es", "de"],
                "performance": {
                    "speed": "15x faster than Whisper-Large",
                    "accuracy": "SOTA performance on multiple benchmarks"
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ FunAudioLLMå¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return {
                "available": False,
                "error": str(e),
                "message": "FunAudioLLMæœåŠ¡å¼‚å¸¸"
            }

# åˆ›å»ºå…¨å±€æœåŠ¡å®ä¾‹
funaudio_service = FunAudioLLMService() 