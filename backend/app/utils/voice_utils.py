"""
è¯­éŸ³å¤„ç†å·¥å…·ç±»
"""

import re
import os
import base64
import logging
from typing import List, Optional

logger = logging.getLogger(__name__)


class VoiceProcessor:
    """è¯­éŸ³å¤„ç†å·¥å…·ç±»"""
    
    @staticmethod
    def clean_text_for_speech(text: str) -> str:
        """
        æ¸…ç†æ–‡æœ¬ç”¨äºè¯­éŸ³åˆæˆ
        - ç§»é™¤ <think></think> æ ‡ç­¾åŠå…¶å†…å®¹
        - ç§»é™¤è¡¨æƒ…ç¬¦å·
        - ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        """
        if not text:
            return ''
        
        # ç§»é™¤æ€è€ƒæ ‡ç­¾åŠå…¶å†…å®¹ï¼ˆå¤„ç†åµŒå¥—æ ‡ç­¾ï¼‰
        # ä½¿ç”¨å¾ªç¯å¤„ç†åµŒå¥—çš„æ€è€ƒæ ‡ç­¾
        cleaned = text
        while '<think>' in cleaned:
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¼€å§‹æ ‡ç­¾
            start_pos = cleaned.find('<think>')
            if start_pos == -1:
                break
            
            # ä»å¼€å§‹æ ‡ç­¾ä½ç½®å¼€å§‹ï¼Œæ‰¾åˆ°åŒ¹é…çš„ç»“æŸæ ‡ç­¾
            # éœ€è¦å¤„ç†åµŒå¥—æƒ…å†µ
            pos = start_pos + 7  # len('<think>')
            depth = 1
            end_pos = -1
            
            while pos < len(cleaned) and depth > 0:
                if cleaned[pos:pos+7] == '<think>':
                    depth += 1
                    pos += 7
                elif cleaned[pos:pos+8] == '</think>':
                    depth -= 1
                    if depth == 0:
                        end_pos = pos + 8
                        break
                    pos += 8
                else:
                    pos += 1
            
            if end_pos != -1:
                # æ‰¾åˆ°åŒ¹é…çš„ç»“æŸæ ‡ç­¾ï¼Œç§»é™¤æ•´ä¸ªæ ‡ç­¾åŠå…¶å†…å®¹
                cleaned = cleaned[:start_pos] + cleaned[end_pos:]
            else:
                # æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„ç»“æŸæ ‡ç­¾ï¼Œç§»é™¤ä»å¼€å§‹æ ‡ç­¾åˆ°æ–‡æœ¬æœ«å°¾çš„æ‰€æœ‰å†…å®¹
                cleaned = cleaned[:start_pos]
                break
        
        # ç§»é™¤ä¸å®Œæ•´çš„æ€è€ƒæ ‡ç­¾ï¼ˆåªæœ‰å¼€å§‹æ ‡ç­¾çš„æƒ…å†µï¼‰
        cleaned = re.sub(r'<think>.*$', '', cleaned)
        
        # ç§»é™¤è¡¨æƒ…ç¬¦å·ï¼ˆæ›´å…¨é¢çš„UnicodeèŒƒå›´ï¼‰
        # Emoticons and symbols
        cleaned = re.sub(r'[\U0001F600-\U0001F64F]', '', cleaned)  # è¡¨æƒ…ç¬¦å·
        cleaned = re.sub(r'[\U0001F300-\U0001F5FF]', '', cleaned)  # ç¬¦å·å’Œå›¾æ ‡
        cleaned = re.sub(r'[\U0001F680-\U0001F6FF]', '', cleaned)  # äº¤é€šå’Œåœ°å›¾ç¬¦å·
        cleaned = re.sub(r'[\U0001F700-\U0001F77F]', '', cleaned)  # ç‚¼é‡‘æœ¯ç¬¦å·
        cleaned = re.sub(r'[\U0001F780-\U0001F7FF]', '', cleaned)  # å‡ ä½•å›¾å½¢æ‰©å±•
        cleaned = re.sub(r'[\U0001F800-\U0001F8FF]', '', cleaned)  # è¡¥å……ç®­å¤´-C
        cleaned = re.sub(r'[\U0001F900-\U0001F9FF]', '', cleaned)  # è¡¥å……ç¬¦å·å’Œå›¾æ ‡
        cleaned = re.sub(r'[\U0001FA00-\U0001FA6F]', '', cleaned)  # æ‰©å±•-A
        cleaned = re.sub(r'[\U0001FA70-\U0001FAFF]', '', cleaned)  # ç¬¦å·å’Œå›¾æ ‡æ‰©å±•-A
        cleaned = re.sub(r'[\U00002600-\U000026FF]', '', cleaned)  # æ‚é¡¹ç¬¦å·
        cleaned = re.sub(r'[\U00002700-\U000027BF]', '', cleaned)  # è£…é¥°ç¬¦å·
        cleaned = re.sub(r'[\U0000FE00-\U0000FE0F]', '', cleaned)  # å˜ä½“é€‰æ‹©å™¨
        
        # ç§»é™¤Markdownæ ¼å¼ï¼ˆå¯é€‰ï¼Œå·²æœ‰çš„æ¸…ç†é€»è¾‘ï¼‰
        cleaned = re.sub(r'\*\*(.*?)\*\*', r'\1', cleaned)
        cleaned = re.sub(r'\*(.*?)\*', r'\1', cleaned)      # æ–œä½“
        cleaned = re.sub(r'`(.*?)`', r'\1', cleaned)        # ä»£ç 
        cleaned = re.sub(r'#{1,6}\s*(.*)', r'\1', cleaned) # æ ‡é¢˜
        cleaned = re.sub(r'\[(.*?)\]\(.*?\)', r'\1', cleaned)  # é“¾æ¥
        
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()
        
        return cleaned

    @staticmethod
    def split_text_for_tts(text: str) -> List[str]:
        """
        æ™ºèƒ½æ–‡æœ¬åˆ†å—ï¼Œç”¨äºTTSåˆæˆ
        è¿”å›å¯ä»¥ç«‹å³åˆæˆçš„å®Œæ•´æ–‡æœ¬å—
        """
        if not text.strip():
            return []
        
        # å…ˆæ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤æ€è€ƒæ ‡ç­¾å’Œè¡¨æƒ…ç¬¦å·
        clean_text = VoiceProcessor.clean_text_for_speech(text)
        
        if not clean_text.strip():
            return []
        
        # æŒ‰å¥å­åˆ†å‰²çš„æ­£åˆ™è¡¨è¾¾å¼ï¼ˆåŒ…å«ä¸­è‹±æ–‡å¥å·ï¼‰
        # ä½¿ç”¨æ›´ç²¾ç¡®çš„åˆ†å‰²æ–¹å¼
        sentences = []
        
        # å…ˆæŒ‰ä¸»è¦å¥å­ç»“æŸç¬¦åˆ†å‰²
        sentence_pattern = r'([.!?ã€‚ï¼ï¼Ÿï¼›;])\s*'
        parts = re.split(sentence_pattern, clean_text)
        
        # é‡æ–°ç»„åˆå¥å­ï¼ˆå°†æ ‡ç‚¹ç¬¦å·é™„åŠ åˆ°å‰é¢çš„å¥å­ï¼‰
        current_sentence = ""
        for i in range(len(parts)):
            if i % 2 == 0:  # æ–‡æœ¬éƒ¨åˆ†
                current_sentence += parts[i]
            else:  # æ ‡ç‚¹ç¬¦å·éƒ¨åˆ†
                current_sentence += parts[i]
                if current_sentence.strip():
                    sentences.append(current_sentence.strip())
                current_sentence = ""
        
        # å¤„ç†æœ€åä¸€ä¸ªæ²¡æœ‰æ ‡ç‚¹çš„éƒ¨åˆ†
        if current_sentence.strip():
            sentences.append(current_sentence.strip())
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¥å­åˆ†éš”ç¬¦ï¼Œå°è¯•æŒ‰é€—å·åˆ†å‰²
        if not sentences and clean_text.strip():
            # å¦‚æœæ–‡æœ¬è¾ƒçŸ­ä¸”æ²¡æœ‰å¥å·ï¼Œç›´æ¥è¿”å›
            if len(clean_text) <= 100:
                return [clean_text.strip()]
            else:
                # æ–‡æœ¬è¾ƒé•¿ä½†æ²¡æœ‰å¥å·ï¼ŒæŒ‰é€—å·åˆ†å‰²
                comma_pattern = r'([,ï¼Œ])\s*'
                comma_parts = re.split(comma_pattern, clean_text)
                
                current_part = ""
                for i in range(len(comma_parts)):
                    if i % 2 == 0:  # æ–‡æœ¬éƒ¨åˆ†
                        current_part += comma_parts[i]
                    else:  # é€—å·éƒ¨åˆ†
                        current_part += comma_parts[i]
                        if current_part.strip():
                            sentences.append(current_part.strip())
                        current_part = ""
                
                # å¤„ç†æœ€åä¸€ä¸ªæ²¡æœ‰é€—å·çš„éƒ¨åˆ†
                if current_part.strip():
                    sentences.append(current_part.strip())
                
                # å¦‚æœè¿˜æ˜¯æ²¡æœ‰åˆ†å‰²å‡ºå¥å­ï¼Œç›´æ¥è¿”å›åŸæ–‡æœ¬
                if not sentences:
                    sentences = [clean_text.strip()]
        
        # å¯¹äºæµå¼TTSï¼Œä¼˜åŒ–åˆ†å—ç­–ç•¥ä»¥æé«˜è¯­éŸ³æµç•…åº¦
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
                
            # å¦‚æœå¥å­æœ¬èº«å°±å¾ˆé•¿ï¼ˆ>120å­—ç¬¦ï¼‰ï¼Œç›´æ¥ä½œä¸ºä¸€ä¸ªå—
            if len(sentence) > 120:
                # å…ˆå¤„ç†å½“å‰ç´¯ç§¯çš„å—
                if current_chunk:
                    chunks.append(current_chunk)
                    current_chunk = ""
                # é•¿å¥å­å•ç‹¬ä½œä¸ºä¸€ä¸ªå—
                chunks.append(sentence)
            # å¦‚æœå¥å­è¾ƒçŸ­ï¼ˆ<40å­—ç¬¦ï¼‰ï¼Œå°è¯•ä¸å‰é¢çš„å¥å­åˆå¹¶
            elif len(sentence) < 40:
                if current_chunk:
                    potential_chunk = current_chunk + " " + sentence
                    # åˆå¹¶åçš„å—ä¸è¶…è¿‡150å­—ç¬¦
                    if len(potential_chunk) <= 150:
                        current_chunk = potential_chunk
                    else:
                        # åˆå¹¶åå¤ªé•¿ï¼Œå…ˆè¾“å‡ºå½“å‰å—
                        chunks.append(current_chunk)
                        current_chunk = sentence
                else:
                    # æ²¡æœ‰å½“å‰å—ï¼Œå¼€å§‹æ–°çš„å—
                    current_chunk = sentence
            else:
                # ä¸­ç­‰é•¿åº¦çš„å¥å­ï¼ˆ40-120å­—ç¬¦ï¼‰
                if current_chunk:
                    # å¦‚æœå½“å‰å—è¾ƒçŸ­ï¼Œå°è¯•åˆå¹¶
                    if len(current_chunk) < 60:
                        potential_chunk = current_chunk + " " + sentence
                        if len(potential_chunk) <= 150:
                            current_chunk = potential_chunk
                        else:
                            # åˆå¹¶åå¤ªé•¿ï¼Œåˆ†åˆ«è¾“å‡º
                            chunks.append(current_chunk)
                            chunks.append(sentence)
                            current_chunk = ""
                    else:
                        # å½“å‰å—å·²ç»è¶³å¤Ÿé•¿ï¼Œåˆ†åˆ«è¾“å‡º
                        chunks.append(current_chunk)
                        chunks.append(sentence)
                        current_chunk = ""
                else:
                    # æ²¡æœ‰å½“å‰å—ï¼Œç›´æ¥è¾“å‡º
                    chunks.append(sentence)
        
        # æ·»åŠ æœ€åä¸€ä¸ªå—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if current_chunk:
            chunks.append(current_chunk)
        
        # è¿‡æ»¤æ‰ç©ºå—å’ŒåªåŒ…å«æ ‡ç‚¹ç¬¦å·çš„å—ï¼Œå¹¶ç¡®ä¿æœ€å°é•¿åº¦
        valid_chunks = []
        for chunk in chunks:
            chunk = chunk.strip()
            if chunk and re.search(r'[\w\u4e00-\u9fff]', chunk):  # åŒ…å«å­—æ¯æˆ–ä¸­æ–‡å­—ç¬¦
                # ç¡®ä¿å—çš„æœ€å°é•¿åº¦ï¼ˆè‡³å°‘8ä¸ªå­—ç¬¦æˆ–3ä¸ªä¸­æ–‡å­—ç¬¦ï¼‰
                text_content = re.sub(r'[^\w\u4e00-\u9fff]', '', chunk)
                if len(text_content) >= 3:  # è‡³å°‘3ä¸ªæœ‰æ•ˆå­—ç¬¦
                    valid_chunks.append(chunk)
                else:
                    # å¤ªçŸ­çš„å—å°è¯•ä¸å‰ä¸€ä¸ªå—åˆå¹¶
                    if valid_chunks:
                        last_chunk = valid_chunks[-1]
                        merged_chunk = last_chunk + " " + chunk
                        if len(merged_chunk) <= 150:
                            valid_chunks[-1] = merged_chunk
                        else:
                            # åˆå¹¶åå¤ªé•¿ï¼Œä¿æŒåŸæ ·ï¼ˆä½†è¿™ç§æƒ…å†µåº”è¯¥å¾ˆå°‘ï¼‰
                            valid_chunks.append(chunk)
                    else:
                        # æ²¡æœ‰å‰ä¸€ä¸ªå—å¯ä»¥åˆå¹¶ï¼Œä½†å¦‚æœå†…å®¹æœ‰æ„ä¹‰å°±ä¿ç•™
                        if len(chunk.strip()) >= 2:
                            valid_chunks.append(chunk)
        
        return valid_chunks

    @staticmethod
    async def synthesize_speech_chunk(text: str) -> Optional[bytes]:
        """åˆæˆå•ä¸ªæ–‡æœ¬å—çš„è¯­éŸ³"""
        try:
            # ç¬¬ä¸€å±‚éªŒè¯ï¼šåŸºæœ¬è¾“å…¥æ£€æŸ¥
            if not text or not isinstance(text, str):
                logger.info("è·³è¿‡TTS: è¾“å…¥æ–‡æœ¬ä¸ºç©ºæˆ–ç±»å‹é”™è¯¯")
                return None
            
            # æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤æ€è€ƒæ ‡ç­¾å’Œè¡¨æƒ…ç¬¦å·
            clean_text = VoiceProcessor.clean_text_for_speech(text.strip())
            
            # ç¬¬äºŒå±‚éªŒè¯ï¼šæ¸…ç†åçš„æ–‡æœ¬æ£€æŸ¥
            if not clean_text or not clean_text.strip():
                logger.info("è·³è¿‡TTS: æ¸…ç†åçš„æ–‡æœ¬ä¸ºç©º")
                return None
            
            # ç¬¬ä¸‰å±‚éªŒè¯ï¼šå†…å®¹æœ‰æ•ˆæ€§æ£€æŸ¥
            import re
            # æ£€æŸ¥æ˜¯å¦åªåŒ…å«æ ‡ç‚¹ç¬¦å·å’Œç©ºç™½å­—ç¬¦
            text_without_punctuation = re.sub(r'[^\w\u4e00-\u9fff]', '', clean_text)
            if not text_without_punctuation:
                logger.info(f"è·³è¿‡TTS: æ–‡æœ¬åªåŒ…å«æ ‡ç‚¹ç¬¦å·, åŸæ–‡: {repr(clean_text[:50])}")
                return None
            
            # ç¬¬å››å±‚éªŒè¯ï¼šæ–‡æœ¬é•¿åº¦æ£€æŸ¥
            if len(clean_text.strip()) < 2:
                logger.info(f"è·³è¿‡TTS: æ–‡æœ¬è¿‡çŸ­, é•¿åº¦: {len(clean_text)}, å†…å®¹: {repr(clean_text)}")
                return None
            
            logger.info(f"ğŸµ å¼€å§‹TTSåˆæˆ: {repr(clean_text[:100])}{'...' if len(clean_text) > 100 else ''}")
                
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
            from app.services.tts_service import tts_service
            
            # è°ƒç”¨TTSæœåŠ¡
            audio_path, file_size = await tts_service.text_to_speech(
                text=clean_text,
                voice="zh-CN-XiaoxiaoNeural",
                rate="+0%",
                volume="+0%"
            )
            
            # è¯»å–éŸ³é¢‘æ–‡ä»¶
            with open(audio_path, "rb") as audio_file:
                audio_data = audio_file.read()
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(audio_path)
            except Exception as e:
                logger.warning(f"æ¸…ç†ä¸´æ—¶TTSæ–‡ä»¶å¤±è´¥: {e}")
            
            logger.info(f"âœ… TTSåˆæˆæˆåŠŸ: {file_size} å­—èŠ‚")
            return audio_data
            
        except ValueError as ve:
            # è¾“å…¥éªŒè¯é”™è¯¯ï¼Œè¿™æ˜¯é¢„æœŸçš„ï¼Œä¸è®°å½•ä¸ºé”™è¯¯
            logger.info(f"è·³è¿‡TTS: {ve}")
            return None
        except Exception as e:
            logger.error(f"âŒ TTSå—åˆæˆå¤±è´¥: {e}, åŸå§‹æ–‡æœ¬: {repr(text[:200] if text else 'None')}")
            return None


# ä¾¿åˆ©å‡½æ•°ï¼Œä¿æŒå‘åå…¼å®¹æ€§
def clean_text_for_speech(text: str) -> str:
    """æ¸…ç†æ–‡æœ¬ç”¨äºè¯­éŸ³åˆæˆ - ä¾¿åˆ©å‡½æ•°"""
    return VoiceProcessor.clean_text_for_speech(text)


def split_text_for_tts(text: str) -> List[str]:
    """æ™ºèƒ½æ–‡æœ¬åˆ†å—ï¼Œç”¨äºTTSåˆæˆ - ä¾¿åˆ©å‡½æ•°"""
    return VoiceProcessor.split_text_for_tts(text)


async def synthesize_speech_chunk(text: str) -> Optional[bytes]:
    """åˆæˆå•ä¸ªæ–‡æœ¬å—çš„è¯­éŸ³ - ä¾¿åˆ©å‡½æ•°"""
    return await VoiceProcessor.synthesize_speech_chunk(text) 